{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FernandoBRdgz/diplomado_ds_mod4/blob/main/4.4%20Modelado%20Secuencial/4.4.4%20An%C3%A1lisis%20de%20sentimientos%20con%20RNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "ChQzpQtCTFK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se definen 10 comentarios de algún restaurante\n",
        "reviews = [\n",
        "          'Never coming back!',\n",
        "          'horrible service',\n",
        "          'rude waitress',\n",
        "          'cold food',\n",
        "          'horrible food!',\n",
        "          'awesome',\n",
        "          'awesome service!',\n",
        "          'rocks',\n",
        "          'nice work',\n",
        "          'couldn\\'t have done better'\n",
        "]\n",
        "\n",
        "# Se definen sus etiquetas. 1 para positivo, 0 para negativo\n",
        "labels = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])"
      ],
      "metadata": {
        "id": "z35iw-QxTLVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenización"
      ],
      "metadata": {
        "id": "8RCztRec3w2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "ZuYz-htGwQeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50\n",
        "oov_tok = '<OOV>'\n",
        "padding_type = 'post'"
      ],
      "metadata": {
        "id": "sWqxbb6vhIgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(reviews)\n",
        "word_index = tokenizer.word_index"
      ],
      "metadata": {
        "id": "TYffw71AhIc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe-Qk8_OharY",
        "outputId": "e999a0bc-591b-4de5-ea0d-f1d18e820918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<OOV>': 1,\n",
              " 'horrible': 2,\n",
              " 'service': 3,\n",
              " 'food': 4,\n",
              " 'awesome': 5,\n",
              " 'never': 6,\n",
              " 'coming': 7,\n",
              " 'back': 8,\n",
              " 'rude': 9,\n",
              " 'waitress': 10,\n",
              " 'cold': 11,\n",
              " 'rocks': 12,\n",
              " 'nice': 13,\n",
              " 'work': 14,\n",
              " \"couldn't\": 15,\n",
              " 'have': 16,\n",
              " 'done': 17,\n",
              " 'better': 18}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTiFjDiC95cL",
        "outputId": "9ce5be29-4838-4ed8-88fd-9bd9450515a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('never', 1),\n",
              "             ('coming', 1),\n",
              "             ('back', 1),\n",
              "             ('horrible', 2),\n",
              "             ('service', 2),\n",
              "             ('rude', 1),\n",
              "             ('waitress', 1),\n",
              "             ('cold', 1),\n",
              "             ('food', 2),\n",
              "             ('awesome', 2),\n",
              "             ('rocks', 1),\n",
              "             ('nice', 1),\n",
              "             ('work', 1),\n",
              "             (\"couldn't\", 1),\n",
              "             ('have', 1),\n",
              "             ('done', 1),\n",
              "             ('better', 1)])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(word_index)\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj1EsyGshe9q",
        "outputId": "d82f62a0-fad1-45fb-a30f-f532fa7974ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_reviews = tokenizer.texts_to_sequences(reviews)\n",
        "tokenized_reviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk2QwXQBTO-l",
        "outputId": "1f96ece1-0101-4dc7-f35c-5df726d9a8b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[6, 7, 8],\n",
              " [2, 3],\n",
              " [9, 10],\n",
              " [11, 4],\n",
              " [2, 4],\n",
              " [5],\n",
              " [5, 3],\n",
              " [12],\n",
              " [13, 14],\n",
              " [15, 16, 17, 18]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max([len(x) for x in tokenized_reviews])\n",
        "max_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQAVo9e7jNa9",
        "outputId": "aac2c478-5e8f-4770-a9e7-2b9d19ac5233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_reviews = pad_sequences(tokenized_reviews, maxlen=max_length, padding=padding_type)\n",
        "print(padded_reviews)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3UOK8HwTQ8B",
        "outputId": "157e22d5-12e4-4637-a505-19a2f6e87e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6  7  8  0]\n",
            " [ 2  3  0  0]\n",
            " [ 9 10  0  0]\n",
            " [11  4  0  0]\n",
            " [ 2  4  0  0]\n",
            " [ 5  0  0  0]\n",
            " [ 5  3  0  0]\n",
            " [12  0  0  0]\n",
            " [13 14  0  0]\n",
            " [15 16 17 18]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Word Embeddings"
      ],
      "metadata": {
        "id": "iBXfY1wf4Rwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Embedding, Dense"
      ],
      "metadata": {
        "id": "B_mc17KOw2Dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = Embedding(input_dim=vocab_size+1, output_dim=8, input_length=max_length)"
      ],
      "metadata": {
        "id": "C6wrYe3yZ8Vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(embedding_layer)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "J3Ml4NCmTS_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJx4UZYUaCde",
        "outputId": "347916b0-05a5-4bb6-e862-9f43b838c36d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 4, 8)              152       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 185\n",
            "Trainable params: 185\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(padded_reviews, labels, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws_fRAAQTXgN",
        "outputId": "979fcf23-f17f-4771-ab63-ccc69dd9eb2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.6899 - accuracy: 0.7000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6878 - accuracy: 0.7000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6858 - accuracy: 0.7000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.8000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6818 - accuracy: 0.9000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6798 - accuracy: 0.9000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6778 - accuracy: 0.9000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6758 - accuracy: 0.9000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6738 - accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6718 - accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6698 - accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6677 - accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6657 - accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6637 - accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6617 - accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6596 - accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6576 - accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6555 - accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6534 - accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6514 - accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6493 - accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6472 - accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6451 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6429 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6408 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6387 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6365 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6344 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6322 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6300 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6278 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6256 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6233 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6211 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6188 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6166 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6143 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6120 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6097 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6074 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6050 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6027 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6003 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.5980 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5956 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5932 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5907 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5883 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5859 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5834 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5809 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5784 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5759 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5734 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5709 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5684 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5658 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5632 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5607 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5581 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5555 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5529 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5502 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5476 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5450 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5423 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5396 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5369 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5343 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5316 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5288 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5261 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5234 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5207 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5179 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5152 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5124 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5096 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5069 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5041 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5013 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4985 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4957 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4929 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4901 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4873 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4845 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4817 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4789 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4760 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4732 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4704 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4675 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4647 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4619 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4590 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4562 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4534 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4505 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4477 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7eff32a0e860>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import spatial"
      ],
      "metadata": {
        "id": "j2hEdTVhnOEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)"
      ],
      "metadata": {
        "id": "LPLumapBniGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer.get_weights()[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpGUGcM0TdBm",
        "outputId": "46d72db3-38e0-431b-9495-64c0343664ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame((embedding_layer.get_weights()[0]), index=['<pad>']+list(word_index.keys()), columns=['dim_'+str(x) for x in range(1,9)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "EvWol-oYtbDE",
        "outputId": "ddfe36bb-bd7e-4766-a665-c98b1e7735c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             dim_1     dim_2     dim_3     dim_4     dim_5     dim_6  \\\n",
              "<pad>    -0.002872 -0.169136  0.081623  0.050798 -0.003134  0.113033   \n",
              "<OOV>    -0.000066 -0.019284  0.020890  0.005598  0.031121 -0.022968   \n",
              "horrible  0.093230  0.092167  0.108238  0.067024 -0.152640  0.151768   \n",
              "service  -0.068107  0.022881  0.070349  0.020305 -0.017185  0.022792   \n",
              "food      0.118229  0.133906 -0.097039 -0.057849  0.146062 -0.145414   \n",
              "awesome  -0.132440 -0.137892 -0.095382 -0.113152  0.090876 -0.093992   \n",
              "never     0.065052  0.084699  0.137119  0.100565 -0.079874  0.117911   \n",
              "coming    0.164593  0.114664 -0.088531 -0.126124  0.089613 -0.077185   \n",
              "back      0.039234  0.046961 -0.052296 -0.100803  0.106401 -0.085425   \n",
              "rude      0.099487  0.075202  0.102889  0.080231 -0.100884  0.125737   \n",
              "waitress  0.169880  0.103409 -0.131836 -0.054567  0.136624 -0.091777   \n",
              "cold      0.121748  0.134471  0.149263  0.093590 -0.066402  0.056640   \n",
              "rocks    -0.144353 -0.134602 -0.079808 -0.122345  0.069470 -0.130775   \n",
              "nice     -0.068952 -0.121672 -0.071825 -0.099876  0.102465 -0.096372   \n",
              "work     -0.171135 -0.086439  0.127185  0.086964 -0.113722  0.087914   \n",
              "couldn't -0.069061 -0.120096 -0.107610 -0.142873  0.059676 -0.097249   \n",
              "have     -0.091130 -0.142745  0.136777  0.056200 -0.124594  0.106003   \n",
              "done     -0.049275 -0.085941  0.067433  0.116110 -0.136102  0.057318   \n",
              "better   -0.140699  0.097970 -0.037971 -0.122425 -0.042895 -0.051557   \n",
              "\n",
              "             dim_7     dim_8  \n",
              "<pad>     0.146987 -0.095296  \n",
              "<OOV>    -0.030236 -0.049565  \n",
              "horrible -0.101885 -0.133817  \n",
              "service  -0.018833 -0.002838  \n",
              "food     -0.143044  0.096243  \n",
              "awesome   0.087166  0.074411  \n",
              "never    -0.141945 -0.058283  \n",
              "coming   -0.107477  0.121547  \n",
              "back      0.124592 -0.148585  \n",
              "rude     -0.147084 -0.146315  \n",
              "waitress -0.117338  0.060067  \n",
              "cold     -0.078875 -0.134595  \n",
              "rocks     0.133626  0.125110  \n",
              "nice      0.122056  0.115724  \n",
              "work      0.111294 -0.134580  \n",
              "couldn't  0.063989  0.088817  \n",
              "have      0.120813 -0.049976  \n",
              "done     -0.120086  0.064951  \n",
              "better   -0.080028  0.119974  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2e13432-9e4c-483b-93db-9ce176db1c95\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dim_1</th>\n",
              "      <th>dim_2</th>\n",
              "      <th>dim_3</th>\n",
              "      <th>dim_4</th>\n",
              "      <th>dim_5</th>\n",
              "      <th>dim_6</th>\n",
              "      <th>dim_7</th>\n",
              "      <th>dim_8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>&lt;pad&gt;</th>\n",
              "      <td>-0.002872</td>\n",
              "      <td>-0.169136</td>\n",
              "      <td>0.081623</td>\n",
              "      <td>0.050798</td>\n",
              "      <td>-0.003134</td>\n",
              "      <td>0.113033</td>\n",
              "      <td>0.146987</td>\n",
              "      <td>-0.095296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>&lt;OOV&gt;</th>\n",
              "      <td>-0.000066</td>\n",
              "      <td>-0.019284</td>\n",
              "      <td>0.020890</td>\n",
              "      <td>0.005598</td>\n",
              "      <td>0.031121</td>\n",
              "      <td>-0.022968</td>\n",
              "      <td>-0.030236</td>\n",
              "      <td>-0.049565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>horrible</th>\n",
              "      <td>0.093230</td>\n",
              "      <td>0.092167</td>\n",
              "      <td>0.108238</td>\n",
              "      <td>0.067024</td>\n",
              "      <td>-0.152640</td>\n",
              "      <td>0.151768</td>\n",
              "      <td>-0.101885</td>\n",
              "      <td>-0.133817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>service</th>\n",
              "      <td>-0.068107</td>\n",
              "      <td>0.022881</td>\n",
              "      <td>0.070349</td>\n",
              "      <td>0.020305</td>\n",
              "      <td>-0.017185</td>\n",
              "      <td>0.022792</td>\n",
              "      <td>-0.018833</td>\n",
              "      <td>-0.002838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>food</th>\n",
              "      <td>0.118229</td>\n",
              "      <td>0.133906</td>\n",
              "      <td>-0.097039</td>\n",
              "      <td>-0.057849</td>\n",
              "      <td>0.146062</td>\n",
              "      <td>-0.145414</td>\n",
              "      <td>-0.143044</td>\n",
              "      <td>0.096243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>awesome</th>\n",
              "      <td>-0.132440</td>\n",
              "      <td>-0.137892</td>\n",
              "      <td>-0.095382</td>\n",
              "      <td>-0.113152</td>\n",
              "      <td>0.090876</td>\n",
              "      <td>-0.093992</td>\n",
              "      <td>0.087166</td>\n",
              "      <td>0.074411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>never</th>\n",
              "      <td>0.065052</td>\n",
              "      <td>0.084699</td>\n",
              "      <td>0.137119</td>\n",
              "      <td>0.100565</td>\n",
              "      <td>-0.079874</td>\n",
              "      <td>0.117911</td>\n",
              "      <td>-0.141945</td>\n",
              "      <td>-0.058283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>coming</th>\n",
              "      <td>0.164593</td>\n",
              "      <td>0.114664</td>\n",
              "      <td>-0.088531</td>\n",
              "      <td>-0.126124</td>\n",
              "      <td>0.089613</td>\n",
              "      <td>-0.077185</td>\n",
              "      <td>-0.107477</td>\n",
              "      <td>0.121547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>back</th>\n",
              "      <td>0.039234</td>\n",
              "      <td>0.046961</td>\n",
              "      <td>-0.052296</td>\n",
              "      <td>-0.100803</td>\n",
              "      <td>0.106401</td>\n",
              "      <td>-0.085425</td>\n",
              "      <td>0.124592</td>\n",
              "      <td>-0.148585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rude</th>\n",
              "      <td>0.099487</td>\n",
              "      <td>0.075202</td>\n",
              "      <td>0.102889</td>\n",
              "      <td>0.080231</td>\n",
              "      <td>-0.100884</td>\n",
              "      <td>0.125737</td>\n",
              "      <td>-0.147084</td>\n",
              "      <td>-0.146315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>waitress</th>\n",
              "      <td>0.169880</td>\n",
              "      <td>0.103409</td>\n",
              "      <td>-0.131836</td>\n",
              "      <td>-0.054567</td>\n",
              "      <td>0.136624</td>\n",
              "      <td>-0.091777</td>\n",
              "      <td>-0.117338</td>\n",
              "      <td>0.060067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cold</th>\n",
              "      <td>0.121748</td>\n",
              "      <td>0.134471</td>\n",
              "      <td>0.149263</td>\n",
              "      <td>0.093590</td>\n",
              "      <td>-0.066402</td>\n",
              "      <td>0.056640</td>\n",
              "      <td>-0.078875</td>\n",
              "      <td>-0.134595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rocks</th>\n",
              "      <td>-0.144353</td>\n",
              "      <td>-0.134602</td>\n",
              "      <td>-0.079808</td>\n",
              "      <td>-0.122345</td>\n",
              "      <td>0.069470</td>\n",
              "      <td>-0.130775</td>\n",
              "      <td>0.133626</td>\n",
              "      <td>0.125110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nice</th>\n",
              "      <td>-0.068952</td>\n",
              "      <td>-0.121672</td>\n",
              "      <td>-0.071825</td>\n",
              "      <td>-0.099876</td>\n",
              "      <td>0.102465</td>\n",
              "      <td>-0.096372</td>\n",
              "      <td>0.122056</td>\n",
              "      <td>0.115724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>work</th>\n",
              "      <td>-0.171135</td>\n",
              "      <td>-0.086439</td>\n",
              "      <td>0.127185</td>\n",
              "      <td>0.086964</td>\n",
              "      <td>-0.113722</td>\n",
              "      <td>0.087914</td>\n",
              "      <td>0.111294</td>\n",
              "      <td>-0.134580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>couldn't</th>\n",
              "      <td>-0.069061</td>\n",
              "      <td>-0.120096</td>\n",
              "      <td>-0.107610</td>\n",
              "      <td>-0.142873</td>\n",
              "      <td>0.059676</td>\n",
              "      <td>-0.097249</td>\n",
              "      <td>0.063989</td>\n",
              "      <td>0.088817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>have</th>\n",
              "      <td>-0.091130</td>\n",
              "      <td>-0.142745</td>\n",
              "      <td>0.136777</td>\n",
              "      <td>0.056200</td>\n",
              "      <td>-0.124594</td>\n",
              "      <td>0.106003</td>\n",
              "      <td>0.120813</td>\n",
              "      <td>-0.049976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>done</th>\n",
              "      <td>-0.049275</td>\n",
              "      <td>-0.085941</td>\n",
              "      <td>0.067433</td>\n",
              "      <td>0.116110</td>\n",
              "      <td>-0.136102</td>\n",
              "      <td>0.057318</td>\n",
              "      <td>-0.120086</td>\n",
              "      <td>0.064951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>better</th>\n",
              "      <td>-0.140699</td>\n",
              "      <td>0.097970</td>\n",
              "      <td>-0.037971</td>\n",
              "      <td>-0.122425</td>\n",
              "      <td>-0.042895</td>\n",
              "      <td>-0.051557</td>\n",
              "      <td>-0.080028</td>\n",
              "      <td>0.119974</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2e13432-9e4c-483b-93db-9ce176db1c95')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d2e13432-9e4c-483b-93db-9ce176db1c95 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d2e13432-9e4c-483b-93db-9ce176db1c95');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "computed_similarities = pd.DataFrame()\n",
        "\n",
        "for word1 in word_index.keys():\n",
        "    for word2 in word_index.keys():\n",
        "        idx1 = word_index[word1]\n",
        "        idx2 = word_index[word2]\n",
        "        embedding1 = embedding_layer.get_weights()[0][idx1]\n",
        "        embedding2 = embedding_layer.get_weights()[0][idx2]\n",
        "        similarity = cosine_similarity(embedding1, embedding2)\n",
        "        computed_similarities.loc[word1, word2] = similarity"
      ],
      "metadata": {
        "id": "FhL4ADNanncK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def non_zero_green(val):\n",
        "    return 'background-color: Aquamarine' if (val > 0.9) & (val < 1) else ''"
      ],
      "metadata": {
        "id": "Jb3PzDVFr1T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "computed_similarities.style.applymap(non_zero_green)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "53N-c7pCqNK9",
        "outputId": "7d0e5ba3-5b49-43cd-b4bf-2f4abb4094a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7efeab5ef760>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_bea7f_row1_col5, #T_bea7f_row1_col8, #T_bea7f_row3_col6, #T_bea7f_row3_col9, #T_bea7f_row4_col11, #T_bea7f_row4_col12, #T_bea7f_row4_col14, #T_bea7f_row5_col1, #T_bea7f_row5_col8, #T_bea7f_row6_col3, #T_bea7f_row6_col9, #T_bea7f_row8_col1, #T_bea7f_row8_col5, #T_bea7f_row8_col10, #T_bea7f_row9_col3, #T_bea7f_row9_col6, #T_bea7f_row10_col8, #T_bea7f_row11_col4, #T_bea7f_row11_col12, #T_bea7f_row11_col14, #T_bea7f_row12_col4, #T_bea7f_row12_col11, #T_bea7f_row12_col14, #T_bea7f_row13_col15, #T_bea7f_row14_col4, #T_bea7f_row14_col11, #T_bea7f_row14_col12, #T_bea7f_row15_col13 {\n",
              "  background-color: Aquamarine;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_bea7f\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_bea7f_level0_col0\" class=\"col_heading level0 col0\" ><OOV></th>\n",
              "      <th id=\"T_bea7f_level0_col1\" class=\"col_heading level0 col1\" >horrible</th>\n",
              "      <th id=\"T_bea7f_level0_col2\" class=\"col_heading level0 col2\" >service</th>\n",
              "      <th id=\"T_bea7f_level0_col3\" class=\"col_heading level0 col3\" >food</th>\n",
              "      <th id=\"T_bea7f_level0_col4\" class=\"col_heading level0 col4\" >awesome</th>\n",
              "      <th id=\"T_bea7f_level0_col5\" class=\"col_heading level0 col5\" >never</th>\n",
              "      <th id=\"T_bea7f_level0_col6\" class=\"col_heading level0 col6\" >coming</th>\n",
              "      <th id=\"T_bea7f_level0_col7\" class=\"col_heading level0 col7\" >back</th>\n",
              "      <th id=\"T_bea7f_level0_col8\" class=\"col_heading level0 col8\" >rude</th>\n",
              "      <th id=\"T_bea7f_level0_col9\" class=\"col_heading level0 col9\" >waitress</th>\n",
              "      <th id=\"T_bea7f_level0_col10\" class=\"col_heading level0 col10\" >cold</th>\n",
              "      <th id=\"T_bea7f_level0_col11\" class=\"col_heading level0 col11\" >rocks</th>\n",
              "      <th id=\"T_bea7f_level0_col12\" class=\"col_heading level0 col12\" >nice</th>\n",
              "      <th id=\"T_bea7f_level0_col13\" class=\"col_heading level0 col13\" >work</th>\n",
              "      <th id=\"T_bea7f_level0_col14\" class=\"col_heading level0 col14\" >couldn't</th>\n",
              "      <th id=\"T_bea7f_level0_col15\" class=\"col_heading level0 col15\" >have</th>\n",
              "      <th id=\"T_bea7f_level0_col16\" class=\"col_heading level0 col16\" >done</th>\n",
              "      <th id=\"T_bea7f_level0_col17\" class=\"col_heading level0 col17\" >better</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_bea7f_level0_row0\" class=\"row_heading level0 row0\" ><OOV></th>\n",
              "      <td id=\"T_bea7f_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
              "      <td id=\"T_bea7f_row0_col1\" class=\"data row0 col1\" >0.093842</td>\n",
              "      <td id=\"T_bea7f_row0_col2\" class=\"data row0 col2\" >0.097693</td>\n",
              "      <td id=\"T_bea7f_row0_col3\" class=\"data row0 col3\" >0.096775</td>\n",
              "      <td id=\"T_bea7f_row0_col4\" class=\"data row0 col4\" >-0.057557</td>\n",
              "      <td id=\"T_bea7f_row0_col5\" class=\"data row0 col5\" >0.172329</td>\n",
              "      <td id=\"T_bea7f_row0_col6\" class=\"data row0 col6\" >-0.122584</td>\n",
              "      <td id=\"T_bea7f_row0_col7\" class=\"data row0 col7\" >0.309258</td>\n",
              "      <td id=\"T_bea7f_row0_col8\" class=\"data row0 col8\" >0.282958</td>\n",
              "      <td id=\"T_bea7f_row0_col9\" class=\"data row0 col9\" >0.076440</td>\n",
              "      <td id=\"T_bea7f_row0_col10\" class=\"data row0 col10\" >0.287669</td>\n",
              "      <td id=\"T_bea7f_row0_col11\" class=\"data row0 col11\" >-0.187660</td>\n",
              "      <td id=\"T_bea7f_row0_col12\" class=\"data row0 col12\" >-0.171752</td>\n",
              "      <td id=\"T_bea7f_row0_col13\" class=\"data row0 col13\" >0.101769</td>\n",
              "      <td id=\"T_bea7f_row0_col14\" class=\"data row0 col14\" >-0.142603</td>\n",
              "      <td id=\"T_bea7f_row0_col15\" class=\"data row0 col15\" >-0.067105</td>\n",
              "      <td id=\"T_bea7f_row0_col16\" class=\"data row0 col16\" >-0.072005</td>\n",
              "      <td id=\"T_bea7f_row0_col17\" class=\"data row0 col17\" >-0.349253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bea7f_level0_row1\" class=\"row_heading level0 row1\" >horrible</th>\n",
              "      <td id=\"T_bea7f_row1_col0\" class=\"data row1 col0\" >0.093842</td>\n",
              "      <td id=\"T_bea7f_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
              "      <td id=\"T_bea7f_row1_col2\" class=\"data row1 col2\" >0.368913</td>\n",
              "      <td id=\"T_bea7f_row1_col3\" class=\"data row1 col3\" >-0.299805</td>\n",
              "      <td id=\"T_bea7f_row1_col4\" class=\"data row1 col4\" >-0.918938</td>\n",
              "      <td id=\"T_bea7f_row1_col5\" class=\"data row1 col5\" >0.920952</td>\n",
              "      <td id=\"T_bea7f_row1_col6\" class=\"data row1 col6\" >-0.215094</td>\n",
              "      <td id=\"T_bea7f_row1_col7\" class=\"data row1 col7\" >-0.298124</td>\n",
              "      <td id=\"T_bea7f_row1_col8\" class=\"data row1 col8\" >0.971423</td>\n",
              "      <td id=\"T_bea7f_row1_col9\" class=\"data row1 col9\" >-0.220611</td>\n",
              "      <td id=\"T_bea7f_row1_col10\" class=\"data row1 col10\" >0.893650</td>\n",
              "      <td id=\"T_bea7f_row1_col11\" class=\"data row1 col11\" >-0.925804</td>\n",
              "      <td id=\"T_bea7f_row1_col12\" class=\"data row1 col12\" >-0.955010</td>\n",
              "      <td id=\"T_bea7f_row1_col13\" class=\"data row1 col13\" >0.300891</td>\n",
              "      <td id=\"T_bea7f_row1_col14\" class=\"data row1 col14\" >-0.892946</td>\n",
              "      <td id=\"T_bea7f_row1_col15\" class=\"data row1 col15\" >0.261472</td>\n",
              "      <td id=\"T_bea7f_row1_col16\" class=\"data row1 col16\" >0.414309</td>\n",
              "      <td id=\"T_bea7f_row1_col17\" class=\"data row1 col17\" >-0.291866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bea7f_level0_row2\" class=\"row_heading level0 row2\" >service</th>\n",
              "      <td id=\"T_bea7f_row2_col0\" class=\"data row2 col0\" >0.097693</td>\n",
              "      <td id=\"T_bea7f_row2_col1\" class=\"data row2 col1\" >0.368913</td>\n",
              "      <td id=\"T_bea7f_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
              "      <td id=\"T_bea7f_row2_col3\" class=\"data row2 col3\" >-0.443290</td>\n",
              "      <td id=\"T_bea7f_row2_col4\" class=\"data row2 col4\" >-0.270052</td>\n",
              "      <td id=\"T_bea7f_row2_col5\" class=\"data row2 col5\" >0.512904</td>\n",
              "      <td id=\"T_bea7f_row2_col6\" class=\"data row2 col6\" >-0.543753</td>\n",
              "      <td id=\"T_bea7f_row2_col7\" class=\"data row2 col7\" >-0.446043</td>\n",
              "      <td id=\"T_bea7f_row2_col8\" class=\"data row2 col8\" >0.336330</td>\n",
              "      <td id=\"T_bea7f_row2_col9\" class=\"data row2 col9\" >-0.629144</td>\n",
              "      <td id=\"T_bea7f_row2_col10\" class=\"data row2 col10\" >0.342862</td>\n",
              "      <td id=\"T_bea7f_row2_col11\" class=\"data row2 col11\" >-0.228076</td>\n",
              "      <td id=\"T_bea7f_row2_col12\" class=\"data row2 col12\" >-0.377663</td>\n",
              "      <td id=\"T_bea7f_row2_col13\" class=\"data row2 col13\" >0.626213</td>\n",
              "      <td id=\"T_bea7f_row2_col14\" class=\"data row2 col14\" >-0.442597</td>\n",
              "      <td id=\"T_bea7f_row2_col15\" class=\"data row2 col15\" >0.485251</td>\n",
              "      <td id=\"T_bea7f_row2_col16\" class=\"data row2 col16\" >0.502817</td>\n",
              "      <td id=\"T_bea7f_row2_col17\" class=\"data row2 col17\" >0.256386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bea7f_level0_row3\" class=\"row_heading level0 row3\" >food</th>\n",
              "      <td id=\"T_bea7f_row3_col0\" class=\"data row3 col0\" >0.096775</td>\n",
              "      <td id=\"T_bea7f_row3_col1\" class=\"data row3 col1\" >-0.299805</td>\n",
              "      <td id=\"T_bea7f_row3_col2\" class=\"data row3 col2\" >-0.443290</td>\n",
              "      <td id=\"T_bea7f_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
              "      <td id=\"T_bea7f_row3_col4\" class=\"data row3 col4\" >0.032541</td>\n",
              "      <td id=\"T_bea7f_row3_col5\" class=\"data row3 col5\" >-0.143269</td>\n",
              "      <td id=\"T_bea7f_row3_col6\" class=\"data row3 col6\" >0.924630</td>\n",
              "      <td id=\"T_bea7f_row3_col7\" class=\"data row3 col7\" >0.191524</td>\n",
              "      <td id=\"T_bea7f_row3_col8\" class=\"data row3 col8\" >-0.173021</td>\n",
              "      <td id=\"T_bea7f_row3_col9\" class=\"data row3 col9\" >0.957440</td>\n",
              "      <td id=\"T_bea7f_row3_col10\" class=\"data row3 col10\" >-0.067101</td>\n",
              "      <td id=\"T_bea7f_row3_col11\" class=\"data row3 col11\" >0.015660</td>\n",
              "      <td id=\"T_bea7f_row3_col12\" class=\"data row3 col12\" >0.111445</td>\n",
              "      <td id=\"T_bea7f_row3_col13\" class=\"data row3 col13\" >-0.940567</td>\n",
              "      <td id=\"T_bea7f_row3_col14\" class=\"data row3 col14\" >0.177117</td>\n",
              "      <td id=\"T_bea7f_row3_col15\" class=\"data row3 col15\" >-0.972179</td>\n",
              "      <td id=\"T_bea7f_row3_col16\" class=\"data row3 col16\" >-0.396015</td>\n",
              "      <td id=\"T_bea7f_row3_col17\" class=\"data row3 col17\" >0.345249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bea7f_level0_row4\" class=\"row_heading level0 row4\" >awesome</th>\n",
              "      <td id=\"T_bea7f_row4_col0\" class=\"data row4 col0\" >-0.057557</td>\n",
              "      <td id=\"T_bea7f_row4_col1\" class=\"data row4 col1\" >-0.918938</td>\n",
              "      <td id=\"T_bea7f_row4_col2\" class=\"data row4 col2\" >-0.270052</td>\n",
              "      <td id=\"T_bea7f_row4_col3\" class=\"data row4 col3\" >0.032541</td>\n",
              "      <td id=\"T_bea7f_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
              "      <td id=\"T_bea7f_row4_col5\" class=\"data row4 col5\" >-0.923799</td>\n",
              "      <td id=\"T_bea7f_row4_col6\" class=\"data row4 col6\" >0.001873</td>\n",
              "      <td id=\"T_bea7f_row4_col7\" class=\"data row4 col7\" >0.276487</td>\n",
              "      <td id=\"T_bea7f_row4_col8\" class=\"data row4 col8\" >-0.917909</td>\n",
              "      <td id=\"T_bea7f_row4_col9\" class=\"data row4 col9\" >-0.028322</td>\n",
              "      <td id=\"T_bea7f_row4_col10\" class=\"data row4 col10\" >-0.951443</td>\n",
              "      <td id=\"T_bea7f_row4_col11\" class=\"data row4 col11\" >0.974223</td>\n",
              "      <td id=\"T_bea7f_row4_col12\" class=\"data row4 col12\" >0.953388</td>\n",
              "      <td id=\"T_bea7f_row4_col13\" class=\"data row4 col13\" >-0.063291</td>\n",
              "      <td id=\"T_bea7f_row4_col14\" class=\"data row4 col14\" >0.959726</td>\n",
              "      <td id=\"T_bea7f_row4_col15\" class=\"data row4 col15\" >-0.023241</td>\n",
              "      <td id=\"T_bea7f_row4_col16\" class=\"data row4 col16\" >-0.315897</td>\n",
              "      <td id=\"T_bea7f_row4_col17\" class=\"data row4 col17\" >0.321069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bea7f_level0_row5\" class=\"row_heading level0 row5\" >never</th>\n",
              "      <td id=\"T_bea7f_row5_col0\" class=\"data row5 col0\" >0.172329</td>\n",
              "      <td id=\"T_bea7f_row5_col1\" class=\"data row5 col1\" >0.920952</td>\n",
              "      <td id=\"T_bea7f_row5_col2\" class=\"data row5 col2\" >0.512904</td>\n",
              "      <td id=\"T_bea7f_row5_col3\" class=\"data row5 col3\" >-0.143269</td>\n",
              "      <td id=\"T_bea7f_row5_col4\" class=\"data row5 col4\" >-0.923799</td>\n",
              "      <td id=\"T_bea7f_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
              "      <td id=\"T_bea7f_row5_col6\" class=\"data row5 col6\" >-0.133333</td>\n",
              "      <td id=\"T_bea7f_row5_col7\" class=\"data row5 col7\" >-0.490091</td>\n",
              "      <td id=\"T_bea7f_row5_col8\" class=\"data row5 col8\" >0.944207</td>\n",
              "      <td id=\"T_bea7f_row5_col9\" class=\"data row5 col9\" >-0.131616</td>\n",
              "      <td id=\"T_bea7f_row5_col10\" class=\"data row5 col10\" >0.892905</td>\n",
              "      <td id=\"T_bea7f_row5_col11\" class=\"data row5 col11\" >-0.924831</td>\n",
              "      <td id=\"T_bea7f_row5_col12\" class=\"data row5 col12\" >-0.938234</td>\n",
              "      <td id=\"T_bea7f_row5_col13\" class=\"data row5 col13\" >0.198352</td>\n",
              "      <td id=\"T_bea7f_row5_col14\" class=\"data row5 col14\" >-0.927711</td>\n",
              "      <td id=\"T_bea7f_row5_col15\" class=\"data row5 col15\" >0.163839</td>\n",
              "      <td id=\"T_bea7f_row5_col16\" class=\"data row5 col16\" >0.545178</td>\n",
              "      <td id=\"T_bea7f_row5_col17\" class=\"data row5 col17\" >-0.215339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bea7f_level0_row6\" class=\"row_heading level0 row6\" >coming</th>\n",
              "      <td id=\"T_bea7f_row6_col0\" class=\"data row6 col0\" >-0.122584</td>\n",
              "      <td id=\"T_bea7f_row6_col1\" class=\"data row6 col1\" >-0.215094</td>\n",
              "      <td id=\"T_bea7f_row6_col2\" class=\"data row6 col2\" >-0.543753</td>\n",
              "      <td id=\"T_bea7f_row6_col3\" class=\"data row6 col3\" >0.924630</td>\n",
              "      <td id=\"T_bea7f_row6_col4\" class=\"data row6 col4\" >0.001873</td>\n",
              "      <td id=\"T_bea7f_row6_col5\" class=\"data row6 col5\" >-0.133333</td>\n",
              "      <td id=\"T_bea7f_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
              "      <td id=\"T_bea7f_row6_col7\" class=\"data row6 col7\" >0.159035</td>\n",
              "      <td id=\"T_bea7f_row6_col8\" class=\"data row6 col8\" >-0.145241</td>\n",
              "      <td id=\"T_bea7f_row6_col9\" class=\"data row6 col9\" >0.935544</td>\n",
              "      <td id=\"T_bea7f_row6_col10\" class=\"data row6 col10\" >-0.077643</td>\n",
              "      <td id=\"T_bea7f_row6_col11\" class=\"data row6 col11\" >0.004250</td>\n",
              "      <td id=\"T_bea7f_row6_col12\" class=\"data row6 col12\" >0.120797</td>\n",
              "      <td id=\"T_bea7f_row6_col13\" class=\"data row6 col13\" >-0.978583</td>\n",
              "      <td id=\"T_bea7f_row6_col14\" class=\"data row6 col14\" >0.215176</td>\n",
              "      <td id=\"T_bea7f_row6_col15\" class=\"data row6 col15\" >-0.896648</td>\n",
              "      <td id=\"T_bea7f_row6_col16\" class=\"data row6 col16\" >-0.407587</td>\n",
              "      <td id=\"T_bea7f_row6_col17\" class=\"data row6 col17\" >0.350616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bea7f_level0_row7\" class=\"row_heading level0 row7\" >back</th>\n",
              "      <td id=\"T_bea7f_row7_col0\" class=\"data row7 col0\" >0.309258</td>\n",
              "      <td id=\"T_bea7f_row7_col1\" class=\"data row7 col1\" >-0.298124</td>\n",
              "      <td id=\"T_bea7f_row7_col2\" class=\"data row7 col2\" >-0.446043</td>\n",
              "      <td id=\"T_bea7f_row7_col3\" class=\"data row7 col3\" >0.191524</td>\n",
              "      <td id=\"T_bea7f_row7_col4\" class=\"data row7 col4\" >0.276487</td>\n",
              "      <td id=\"T_bea7f_row7_col5\" class=\"data row7 col5\" >-0.490091</td>\n",
              "      <td id=\"T_bea7f_row7_col6\" class=\"data row7 col6\" >0.159035</td>\n",
              "      <td id=\"T_bea7f_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
              "      <td id=\"T_bea7f_row7_col8\" class=\"data row7 col8\" >-0.280029</td>\n",
              "      <td id=\"T_bea7f_row7_col9\" class=\"data row7 col9\" >0.260863</td>\n",
              "      <td id=\"T_bea7f_row7_col10\" class=\"data row7 col10\" >-0.094277</td>\n",
              "      <td id=\"T_bea7f_row7_col11\" class=\"data row7 col11\" >0.230264</td>\n",
              "      <td id=\"T_bea7f_row7_col12\" class=\"data row7 col12\" >0.290410</td>\n",
              "      <td id=\"T_bea7f_row7_col13\" class=\"data row7 col13\" >-0.132360</td>\n",
              "      <td id=\"T_bea7f_row7_col14\" class=\"data row7 col14\" >0.283380</td>\n",
              "      <td id=\"T_bea7f_row7_col15\" class=\"data row7 col15\" >-0.276498</td>\n",
              "      <td id=\"T_bea7f_row7_col16\" class=\"data row7 col16\" >-0.924177</td>\n",
              "      <td id=\"T_bea7f_row7_col17\" class=\"data row7 col17\" >-0.202124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bea7f_level0_row8\" class=\"row_heading level0 row8\" >rude</th>\n",
              "      <td id=\"T_bea7f_row8_col0\" class=\"data row8 col0\" >0.282958</td>\n",
              "      <td id=\"T_bea7f_row8_col1\" class=\"data row8 col1\" >0.971423</td>\n",
              "      <td id=\"T_bea7f_row8_col2\" class=\"data row8 col2\" >0.336330</td>\n",
              "      <td id=\"T_bea7f_row8_col3\" class=\"data row8 col3\" >-0.173021</td>\n",
              "      <td id=\"T_bea7f_row8_col4\" class=\"data row8 col4\" >-0.917909</td>\n",
              "      <td id=\"T_bea7f_row8_col5\" class=\"data row8 col5\" >0.944207</td>\n",
              "      <td id=\"T_bea7f_row8_col6\" class=\"data row8 col6\" >-0.145241</td>\n",
              "      <td id=\"T_bea7f_row8_col7\" class=\"data row8 col7\" >-0.280029</td>\n",
              "      <td id=\"T_bea7f_row8_col8\" class=\"data row8 col8\" >1.000000</td>\n",
              "      <td id=\"T_bea7f_row8_col9\" class=\"data row8 col9\" >-0.098252</td>\n",
              "      <td id=\"T_bea7f_row8_col10\" class=\"data row8 col10\" >0.913850</td>\n",
              "      <td id=\"T_bea7f_row8_col11\" class=\"data row8 col11\" >-0.958359</td>\n",
              "      <td id=\"T_bea7f_row8_col12\" class=\"data row8 col12\" >-0.967804</td>\n",
              "      <td id=\"T_bea7f_row8_col13\" class=\"data row8 col13\" >0.210164</td>\n",
              "      <td id=\"T_bea7f_row8_col14\" class=\"data row8 col14\" >-0.898949</td>\n",
              "      <td id=\"T_bea7f_row8_col15\" class=\"data row8 col15\" >0.145208</td>\n",
              "      <td id=\"T_bea7f_row8_col16\" class=\"data row8 col16\" >0.407994</td>\n",
              "      <td id=\"T_bea7f_row8_col17\" class=\"data row8 col17\" >-0.332885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bea7f_level0_row9\" class=\"row_heading level0 row9\" >waitress</th>\n",
              "      <td id=\"T_bea7f_row9_col0\" class=\"data row9 col0\" >0.076440</td>\n",
              "      <td id=\"T_bea7f_row9_col1\" class=\"data row9 col1\" >-0.220611</td>\n",
              "      <td id=\"T_bea7f_row9_col2\" class=\"data row9 col2\" >-0.629144</td>\n",
              "      <td id=\"T_bea7f_row9_col3\" class=\"data row9 col3\" >0.957440</td>\n",
              "      <td id=\"T_bea7f_row9_col4\" class=\"data row9 col4\" >-0.028322</td>\n",
              "      <td id=\"T_bea7f_row9_col5\" class=\"data row9 col5\" >-0.131616</td>\n",
              "      <td id=\"T_bea7f_row9_col6\" class=\"data row9 col6\" >0.935544</td>\n",
              "      <td id=\"T_bea7f_row9_col7\" class=\"data row9 col7\" >0.260863</td>\n",
              "      <td id=\"T_bea7f_row9_col8\" class=\"data row9 col8\" >-0.098252</td>\n",
              "      <td id=\"T_bea7f_row9_col9\" class=\"data row9 col9\" >1.000000</td>\n",
              "      <td id=\"T_bea7f_row9_col10\" class=\"data row9 col10\" >-0.032956</td>\n",
              "      <td id=\"T_bea7f_row9_col11\" class=\"data row9 col11\" >-0.072016</td>\n",
              "      <td id=\"T_bea7f_row9_col12\" class=\"data row9 col12\" >0.065597</td>\n",
              "      <td id=\"T_bea7f_row9_col13\" class=\"data row9 col13\" >-0.965884</td>\n",
              "      <td id=\"T_bea7f_row9_col14\" class=\"data row9 col14\" >0.142834</td>\n",
              "      <td id=\"T_bea7f_row9_col15\" class=\"data row9 col15\" >-0.959771</td>\n",
              "      <td id=\"T_bea7f_row9_col16\" class=\"data row9 col16\" >-0.454202</td>\n",
              "      <td id=\"T_bea7f_row9_col17\" class=\"data row9 col17\" >0.155336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bea7f_level0_row10\" class=\"row_heading level0 row10\" >cold</th>\n",
              "      <td id=\"T_bea7f_row10_col0\" class=\"data row10 col0\" >0.287669</td>\n",
              "      <td id=\"T_bea7f_row10_col1\" class=\"data row10 col1\" >0.893650</td>\n",
              "      <td id=\"T_bea7f_row10_col2\" class=\"data row10 col2\" >0.342862</td>\n",
              "      <td id=\"T_bea7f_row10_col3\" class=\"data row10 col3\" >-0.067101</td>\n",
              "      <td id=\"T_bea7f_row10_col4\" class=\"data row10 col4\" >-0.951443</td>\n",
              "      <td id=\"T_bea7f_row10_col5\" class=\"data row10 col5\" >0.892905</td>\n",
              "      <td id=\"T_bea7f_row10_col6\" class=\"data row10 col6\" >-0.077643</td>\n",
              "      <td id=\"T_bea7f_row10_col7\" class=\"data row10 col7\" >-0.094277</td>\n",
              "      <td id=\"T_bea7f_row10_col8\" class=\"data row10 col8\" >0.913850</td>\n",
              "      <td id=\"T_bea7f_row10_col9\" class=\"data row10 col9\" >-0.032956</td>\n",
              "      <td id=\"T_bea7f_row10_col10\" class=\"data row10 col10\" >1.000000</td>\n",
              "      <td id=\"T_bea7f_row10_col11\" class=\"data row10 col11\" >-0.934391</td>\n",
              "      <td id=\"T_bea7f_row10_col12\" class=\"data row10 col12\" >-0.923651</td>\n",
              "      <td id=\"T_bea7f_row10_col13\" class=\"data row10 col13\" >0.159747</td>\n",
              "      <td id=\"T_bea7f_row10_col14\" class=\"data row10 col14\" >-0.941356</td>\n",
              "      <td id=\"T_bea7f_row10_col15\" class=\"data row10 col15\" >0.072099</td>\n",
              "      <td id=\"T_bea7f_row10_col16\" class=\"data row10 col16\" >0.202530</td>\n",
              "      <td id=\"T_bea7f_row10_col17\" class=\"data row10 col17\" >-0.375232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bea7f_level0_row11\" class=\"row_heading level0 row11\" >rocks</th>\n",
              "      <td id=\"T_bea7f_row11_col0\" class=\"data row11 col0\" >-0.187660</td>\n",
              "      <td id=\"T_bea7f_row11_col1\" class=\"data row11 col1\" >-0.925804</td>\n",
              "      <td id=\"T_bea7f_row11_col2\" class=\"data row11 col2\" >-0.228076</td>\n",
              "      <td id=\"T_bea7f_row11_col3\" class=\"data row11 col3\" >0.015660</td>\n",
              "      <td id=\"T_bea7f_row11_col4\" class=\"data row11 col4\" >0.974223</td>\n",
              "      <td id=\"T_bea7f_row11_col5\" class=\"data row11 col5\" >-0.924831</td>\n",
              "      <td id=\"T_bea7f_row11_col6\" class=\"data row11 col6\" >0.004250</td>\n",
              "      <td id=\"T_bea7f_row11_col7\" class=\"data row11 col7\" >0.230264</td>\n",
              "      <td id=\"T_bea7f_row11_col8\" class=\"data row11 col8\" >-0.958359</td>\n",
              "      <td id=\"T_bea7f_row11_col9\" class=\"data row11 col9\" >-0.072016</td>\n",
              "      <td id=\"T_bea7f_row11_col10\" class=\"data row11 col10\" >-0.934391</td>\n",
              "      <td id=\"T_bea7f_row11_col11\" class=\"data row11 col11\" >1.000000</td>\n",
              "      <td id=\"T_bea7f_row11_col12\" class=\"data row11 col12\" >0.968532</td>\n",
              "      <td id=\"T_bea7f_row11_col13\" class=\"data row11 col13\" >-0.051146</td>\n",
              "      <td id=\"T_bea7f_row11_col14\" class=\"data row11 col14\" >0.944929</td>\n",
              "      <td id=\"T_bea7f_row11_col15\" class=\"data row11 col15\" >0.018659</td>\n",
              "      <td id=\"T_bea7f_row11_col16\" class=\"data row11 col16\" >-0.289963</td>\n",
              "      <td id=\"T_bea7f_row11_col17\" class=\"data row11 col17\" >0.366061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bea7f_level0_row12\" class=\"row_heading level0 row12\" >nice</th>\n",
              "      <td id=\"T_bea7f_row12_col0\" class=\"data row12 col0\" >-0.171752</td>\n",
              "      <td id=\"T_bea7f_row12_col1\" class=\"data row12 col1\" >-0.955010</td>\n",
              "      <td id=\"T_bea7f_row12_col2\" class=\"data row12 col2\" >-0.377663</td>\n",
              "      <td id=\"T_bea7f_row12_col3\" class=\"data row12 col3\" >0.111445</td>\n",
              "      <td id=\"T_bea7f_row12_col4\" class=\"data row12 col4\" >0.953388</td>\n",
              "      <td id=\"T_bea7f_row12_col5\" class=\"data row12 col5\" >-0.938234</td>\n",
              "      <td id=\"T_bea7f_row12_col6\" class=\"data row12 col6\" >0.120797</td>\n",
              "      <td id=\"T_bea7f_row12_col7\" class=\"data row12 col7\" >0.290410</td>\n",
              "      <td id=\"T_bea7f_row12_col8\" class=\"data row12 col8\" >-0.967804</td>\n",
              "      <td id=\"T_bea7f_row12_col9\" class=\"data row12 col9\" >0.065597</td>\n",
              "      <td id=\"T_bea7f_row12_col10\" class=\"data row12 col10\" >-0.923651</td>\n",
              "      <td id=\"T_bea7f_row12_col11\" class=\"data row12 col11\" >0.968532</td>\n",
              "      <td id=\"T_bea7f_row12_col12\" class=\"data row12 col12\" >1.000000</td>\n",
              "      <td id=\"T_bea7f_row12_col13\" class=\"data row12 col13\" >-0.183269</td>\n",
              "      <td id=\"T_bea7f_row12_col14\" class=\"data row12 col14\" >0.943817</td>\n",
              "      <td id=\"T_bea7f_row12_col15\" class=\"data row12 col15\" >-0.065671</td>\n",
              "      <td id=\"T_bea7f_row12_col16\" class=\"data row12 col16\" >-0.388340</td>\n",
              "      <td id=\"T_bea7f_row12_col17\" class=\"data row12 col17\" >0.227114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bea7f_level0_row13\" class=\"row_heading level0 row13\" >work</th>\n",
              "      <td id=\"T_bea7f_row13_col0\" class=\"data row13 col0\" >0.101769</td>\n",
              "      <td id=\"T_bea7f_row13_col1\" class=\"data row13 col1\" >0.300891</td>\n",
              "      <td id=\"T_bea7f_row13_col2\" class=\"data row13 col2\" >0.626213</td>\n",
              "      <td id=\"T_bea7f_row13_col3\" class=\"data row13 col3\" >-0.940567</td>\n",
              "      <td id=\"T_bea7f_row13_col4\" class=\"data row13 col4\" >-0.063291</td>\n",
              "      <td id=\"T_bea7f_row13_col5\" class=\"data row13 col5\" >0.198352</td>\n",
              "      <td id=\"T_bea7f_row13_col6\" class=\"data row13 col6\" >-0.978583</td>\n",
              "      <td id=\"T_bea7f_row13_col7\" class=\"data row13 col7\" >-0.132360</td>\n",
              "      <td id=\"T_bea7f_row13_col8\" class=\"data row13 col8\" >0.210164</td>\n",
              "      <td id=\"T_bea7f_row13_col9\" class=\"data row13 col9\" >-0.965884</td>\n",
              "      <td id=\"T_bea7f_row13_col10\" class=\"data row13 col10\" >0.159747</td>\n",
              "      <td id=\"T_bea7f_row13_col11\" class=\"data row13 col11\" >-0.051146</td>\n",
              "      <td id=\"T_bea7f_row13_col12\" class=\"data row13 col12\" >-0.183269</td>\n",
              "      <td id=\"T_bea7f_row13_col13\" class=\"data row13 col13\" >1.000000</td>\n",
              "      <td id=\"T_bea7f_row13_col14\" class=\"data row13 col14\" >-0.261067</td>\n",
              "      <td id=\"T_bea7f_row13_col15\" class=\"data row13 col15\" >0.914385</td>\n",
              "      <td id=\"T_bea7f_row13_col16\" class=\"data row13 col16\" >0.377293</td>\n",
              "      <td id=\"T_bea7f_row13_col17\" class=\"data row13 col17\" >-0.275752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bea7f_level0_row14\" class=\"row_heading level0 row14\" >couldn't</th>\n",
              "      <td id=\"T_bea7f_row14_col0\" class=\"data row14 col0\" >-0.142603</td>\n",
              "      <td id=\"T_bea7f_row14_col1\" class=\"data row14 col1\" >-0.892946</td>\n",
              "      <td id=\"T_bea7f_row14_col2\" class=\"data row14 col2\" >-0.442597</td>\n",
              "      <td id=\"T_bea7f_row14_col3\" class=\"data row14 col3\" >0.177117</td>\n",
              "      <td id=\"T_bea7f_row14_col4\" class=\"data row14 col4\" >0.959726</td>\n",
              "      <td id=\"T_bea7f_row14_col5\" class=\"data row14 col5\" >-0.927711</td>\n",
              "      <td id=\"T_bea7f_row14_col6\" class=\"data row14 col6\" >0.215176</td>\n",
              "      <td id=\"T_bea7f_row14_col7\" class=\"data row14 col7\" >0.283380</td>\n",
              "      <td id=\"T_bea7f_row14_col8\" class=\"data row14 col8\" >-0.898949</td>\n",
              "      <td id=\"T_bea7f_row14_col9\" class=\"data row14 col9\" >0.142834</td>\n",
              "      <td id=\"T_bea7f_row14_col10\" class=\"data row14 col10\" >-0.941356</td>\n",
              "      <td id=\"T_bea7f_row14_col11\" class=\"data row14 col11\" >0.944929</td>\n",
              "      <td id=\"T_bea7f_row14_col12\" class=\"data row14 col12\" >0.943817</td>\n",
              "      <td id=\"T_bea7f_row14_col13\" class=\"data row14 col13\" >-0.261067</td>\n",
              "      <td id=\"T_bea7f_row14_col14\" class=\"data row14 col14\" >1.000000</td>\n",
              "      <td id=\"T_bea7f_row14_col15\" class=\"data row14 col15\" >-0.162290</td>\n",
              "      <td id=\"T_bea7f_row14_col16\" class=\"data row14 col16\" >-0.356755</td>\n",
              "      <td id=\"T_bea7f_row14_col17\" class=\"data row14 col17\" >0.373821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bea7f_level0_row15\" class=\"row_heading level0 row15\" >have</th>\n",
              "      <td id=\"T_bea7f_row15_col0\" class=\"data row15 col0\" >-0.067105</td>\n",
              "      <td id=\"T_bea7f_row15_col1\" class=\"data row15 col1\" >0.261472</td>\n",
              "      <td id=\"T_bea7f_row15_col2\" class=\"data row15 col2\" >0.485251</td>\n",
              "      <td id=\"T_bea7f_row15_col3\" class=\"data row15 col3\" >-0.972179</td>\n",
              "      <td id=\"T_bea7f_row15_col4\" class=\"data row15 col4\" >-0.023241</td>\n",
              "      <td id=\"T_bea7f_row15_col5\" class=\"data row15 col5\" >0.163839</td>\n",
              "      <td id=\"T_bea7f_row15_col6\" class=\"data row15 col6\" >-0.896648</td>\n",
              "      <td id=\"T_bea7f_row15_col7\" class=\"data row15 col7\" >-0.276498</td>\n",
              "      <td id=\"T_bea7f_row15_col8\" class=\"data row15 col8\" >0.145208</td>\n",
              "      <td id=\"T_bea7f_row15_col9\" class=\"data row15 col9\" >-0.959771</td>\n",
              "      <td id=\"T_bea7f_row15_col10\" class=\"data row15 col10\" >0.072099</td>\n",
              "      <td id=\"T_bea7f_row15_col11\" class=\"data row15 col11\" >0.018659</td>\n",
              "      <td id=\"T_bea7f_row15_col12\" class=\"data row15 col12\" >-0.065671</td>\n",
              "      <td id=\"T_bea7f_row15_col13\" class=\"data row15 col13\" >0.914385</td>\n",
              "      <td id=\"T_bea7f_row15_col14\" class=\"data row15 col14\" >-0.162290</td>\n",
              "      <td id=\"T_bea7f_row15_col15\" class=\"data row15 col15\" >1.000000</td>\n",
              "      <td id=\"T_bea7f_row15_col16\" class=\"data row15 col16\" >0.470613</td>\n",
              "      <td id=\"T_bea7f_row15_col17\" class=\"data row15 col17\" >-0.354190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bea7f_level0_row16\" class=\"row_heading level0 row16\" >done</th>\n",
              "      <td id=\"T_bea7f_row16_col0\" class=\"data row16 col0\" >-0.072005</td>\n",
              "      <td id=\"T_bea7f_row16_col1\" class=\"data row16 col1\" >0.414309</td>\n",
              "      <td id=\"T_bea7f_row16_col2\" class=\"data row16 col2\" >0.502817</td>\n",
              "      <td id=\"T_bea7f_row16_col3\" class=\"data row16 col3\" >-0.396015</td>\n",
              "      <td id=\"T_bea7f_row16_col4\" class=\"data row16 col4\" >-0.315897</td>\n",
              "      <td id=\"T_bea7f_row16_col5\" class=\"data row16 col5\" >0.545178</td>\n",
              "      <td id=\"T_bea7f_row16_col6\" class=\"data row16 col6\" >-0.407587</td>\n",
              "      <td id=\"T_bea7f_row16_col7\" class=\"data row16 col7\" >-0.924177</td>\n",
              "      <td id=\"T_bea7f_row16_col8\" class=\"data row16 col8\" >0.407994</td>\n",
              "      <td id=\"T_bea7f_row16_col9\" class=\"data row16 col9\" >-0.454202</td>\n",
              "      <td id=\"T_bea7f_row16_col10\" class=\"data row16 col10\" >0.202530</td>\n",
              "      <td id=\"T_bea7f_row16_col11\" class=\"data row16 col11\" >-0.289963</td>\n",
              "      <td id=\"T_bea7f_row16_col12\" class=\"data row16 col12\" >-0.388340</td>\n",
              "      <td id=\"T_bea7f_row16_col13\" class=\"data row16 col13\" >0.377293</td>\n",
              "      <td id=\"T_bea7f_row16_col14\" class=\"data row16 col14\" >-0.356755</td>\n",
              "      <td id=\"T_bea7f_row16_col15\" class=\"data row16 col15\" >0.470613</td>\n",
              "      <td id=\"T_bea7f_row16_col16\" class=\"data row16 col16\" >1.000000</td>\n",
              "      <td id=\"T_bea7f_row16_col17\" class=\"data row16 col17\" >0.029039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bea7f_level0_row17\" class=\"row_heading level0 row17\" >better</th>\n",
              "      <td id=\"T_bea7f_row17_col0\" class=\"data row17 col0\" >-0.349253</td>\n",
              "      <td id=\"T_bea7f_row17_col1\" class=\"data row17 col1\" >-0.291866</td>\n",
              "      <td id=\"T_bea7f_row17_col2\" class=\"data row17 col2\" >0.256386</td>\n",
              "      <td id=\"T_bea7f_row17_col3\" class=\"data row17 col3\" >0.345249</td>\n",
              "      <td id=\"T_bea7f_row17_col4\" class=\"data row17 col4\" >0.321069</td>\n",
              "      <td id=\"T_bea7f_row17_col5\" class=\"data row17 col5\" >-0.215339</td>\n",
              "      <td id=\"T_bea7f_row17_col6\" class=\"data row17 col6\" >0.350616</td>\n",
              "      <td id=\"T_bea7f_row17_col7\" class=\"data row17 col7\" >-0.202124</td>\n",
              "      <td id=\"T_bea7f_row17_col8\" class=\"data row17 col8\" >-0.332885</td>\n",
              "      <td id=\"T_bea7f_row17_col9\" class=\"data row17 col9\" >0.155336</td>\n",
              "      <td id=\"T_bea7f_row17_col10\" class=\"data row17 col10\" >-0.375232</td>\n",
              "      <td id=\"T_bea7f_row17_col11\" class=\"data row17 col11\" >0.366061</td>\n",
              "      <td id=\"T_bea7f_row17_col12\" class=\"data row17 col12\" >0.227114</td>\n",
              "      <td id=\"T_bea7f_row17_col13\" class=\"data row17 col13\" >-0.275752</td>\n",
              "      <td id=\"T_bea7f_row17_col14\" class=\"data row17 col14\" >0.373821</td>\n",
              "      <td id=\"T_bea7f_row17_col15\" class=\"data row17 col15\" >-0.354190</td>\n",
              "      <td id=\"T_bea7f_row17_col16\" class=\"data row17 col16\" >0.029039</td>\n",
              "      <td id=\"T_bea7f_row17_col17\" class=\"data row17 col17\" >1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predicción"
      ],
      "metadata": {
        "id": "HcqwA1KAL-sw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tdJzoA6yhRo",
        "outputId": "09e3d385-d254-4a73-d587-bdea3e3c91ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Never coming back!',\n",
              " 'horrible service',\n",
              " 'rude waitress',\n",
              " 'cold food',\n",
              " 'horrible food!',\n",
              " 'awesome',\n",
              " 'awesome service!',\n",
              " 'rocks',\n",
              " 'nice work',\n",
              " \"couldn't have done better\"]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Se definen comentarios adicionales sobre los que se requiere predecir\n",
        "new_reviews  = [\"Nice!\",\n",
        "               \"rude service\",\n",
        "               \"terrible food\"]\n",
        "\n",
        "# Se convierten a una secuencias\n",
        "sequences = tokenizer.texts_to_sequences(new_reviews)\n",
        "\n",
        "# Se rellenan las secuencias\n",
        "new_padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type)\n",
        "\n",
        "# Se predice el sentimiento\n",
        "print(model.predict(new_padded), '\\n', '----'*3)\n",
        "print(np.where(model.predict(new_padded)>0.5, 1, 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ck-ASvhDqOQ-",
        "outputId": "45f0046a-d5fc-4ab6-a0f8-4c0a8691a82e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n",
            "[[0.6215997 ]\n",
            " [0.41907522]\n",
            " [0.42697784]] \n",
            " ------------\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "[[1]\n",
            " [0]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### RNN"
      ],
      "metadata": {
        "id": "6YmvjDiB99jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import SimpleRNN"
      ],
      "metadata": {
        "id": "2JVr5OCVzKnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_rnn = Sequential()\n",
        "model_rnn.add(embedding_layer)\n",
        "model_rnn.add(SimpleRNN(units=64))\n",
        "model_rnn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "WXU091-l-DJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_rnn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM2dDFqi-uSl",
        "outputId": "d4086451-d4d7-4f52-e976-1bdd7c59fe80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 4, 8)              152       \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 64)                4672      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,889\n",
            "Trainable params: 4,889\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_rnn.fit(padded_reviews, labels, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq_-xAVJ-o0C",
        "outputId": "78ad5a19-20fa-4311-a9ed-1407ebd1b99d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.7597 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7210 - accuracy: 0.1000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6844 - accuracy: 0.7000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6494 - accuracy: 0.9000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6156 - accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5828 - accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5506 - accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5190 - accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4877 - accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4566 - accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4257 - accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3951 - accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3647 - accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3347 - accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3053 - accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2766 - accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2489 - accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2223 - accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1970 - accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1733 - accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1514 - accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1312 - accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1130 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0968 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0825 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0700 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0592 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0500 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0422 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0357 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0302 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0257 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0219 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0187 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0161 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0140 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0122 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0107 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0094 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0083 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0011 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efeaaa6d150>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_rnn.predict(new_padded), '\\n', '----'*3)\n",
        "print(np.where(model_rnn.predict(new_padded)>0.5, 1, 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bORVPGFZ-yEx",
        "outputId": "84076359-235e-4d02-a159-06f4eaa95340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 137ms/step\n",
            "[[0.99892765]\n",
            " [0.00210364]\n",
            " [0.1043565 ]] \n",
            " ------------\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "[[1]\n",
            " [0]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GRU"
      ],
      "metadata": {
        "id": "qRU0bRr5_ka4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GRU"
      ],
      "metadata": {
        "id": "IiMmM6bM-8q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_gru = Sequential()\n",
        "model_gru.add(embedding_layer)\n",
        "model_gru.add(GRU(units=64))\n",
        "model_gru.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_gru.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "aHLZ8Rav_qUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_gru.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8ZBEY3a_4nB",
        "outputId": "ef711aac-5a0a-4336-9e1d-46c5c8b1f0b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 4, 8)              152       \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                14208     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,425\n",
            "Trainable params: 14,425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_gru.fit(padded_reviews, labels, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdnsqgOB_9Y-",
        "outputId": "08d87390-ce47-490d-ea35-5f15be3d214f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.6919 - accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6902 - accuracy: 0.6000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6885 - accuracy: 0.8000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6868 - accuracy: 0.9000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6851 - accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6833 - accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6814 - accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6795 - accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6775 - accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6753 - accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6731 - accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6707 - accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6682 - accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6655 - accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6627 - accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6596 - accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6563 - accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6528 - accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6490 - accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6449 - accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6405 - accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6357 - accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6306 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6250 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6190 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6126 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6055 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5980 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5897 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5809 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5713 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5609 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5498 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5378 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5248 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5109 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4960 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4801 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4631 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4450 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4258 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4056 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3844 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3622 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3392 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3155 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2913 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2668 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2422 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2178 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1940 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1710 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1491 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1286 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1097 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0926 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0775 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0642 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0528 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0431 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0350 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0284 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0230 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0186 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0151 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0123 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0101 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0083 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.8215e-04 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.3289e-04 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.8931e-04 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.5059e-04 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 8.1604e-04 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.8510e-04 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.5728e-04 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.3218e-04 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.0945e-04 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.8880e-04 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.6997e-04 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.5274e-04 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.3694e-04 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.2239e-04 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efeaa824c40>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_gru.predict(new_padded), '\\n', '----'*3)\n",
        "print(np.where(model_gru.predict(new_padded)>0.5, 1, 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyI4_wbt__RV",
        "outputId": "3f93260a-d0fd-44e9-dd3b-a423d9e682e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 315ms/step\n",
            "[[0.9994923 ]\n",
            " [0.00142507]\n",
            " [0.04930305]] \n",
            " ------------\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "[[1]\n",
            " [0]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LSTM"
      ],
      "metadata": {
        "id": "sOnxmnEOAHUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LSTM"
      ],
      "metadata": {
        "id": "FrgV1KpgAEaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm = Sequential()\n",
        "model_lstm.add(embedding_layer)\n",
        "model_lstm.add(LSTM(units=64))\n",
        "model_lstm.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "MouCoRPYANhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tjYuPqnAUoE",
        "outputId": "ef87ebb4-eb06-42d4-8a5c-e1e7f5c94f1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 4, 8)              152       \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                18688     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,905\n",
            "Trainable params: 18,905\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm.fit(padded_reviews, labels, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqE366nsAcS7",
        "outputId": "3ee20411-a0a4-454b-d27a-eea2210b9788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6952 - accuracy: 0.1000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6922 - accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6892 - accuracy: 0.7000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6863 - accuracy: 0.9000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6833 - accuracy: 0.9000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6803 - accuracy: 0.9000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6772 - accuracy: 0.9000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6740 - accuracy: 0.9000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6708 - accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6673 - accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6638 - accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6600 - accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6561 - accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6520 - accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6476 - accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6430 - accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6381 - accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6330 - accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6275 - accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6216 - accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6154 - accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6087 - accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6017 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5941 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5860 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5774 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5682 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5584 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5480 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5368 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5249 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5123 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4989 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4846 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4696 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4538 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4371 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4196 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4014 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3825 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3630 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3429 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3223 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3015 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2805 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2595 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2387 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2182 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1983 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1791 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1609 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1436 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1275 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1126 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0990 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0868 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0758 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0660 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0574 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0499 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0435 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0379 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0330 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0289 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0254 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0224 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0177 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0158 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0142 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0129 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0117 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0107 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0098 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0090 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0083 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0077 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0072 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0068 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efea8381780>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_lstm.predict(new_padded), '\\n', '----'*3)\n",
        "print(np.where(model_lstm.predict(new_padded)>0.5, 1, 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5p_OwFWAeRV",
        "outputId": "70f0a2b7-a88f-4c62-ac4c-9ffa89d4e1ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 358ms/step\n",
            "[[0.997166  ]\n",
            " [0.00397032]\n",
            " [0.04999427]] \n",
            " ------------\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "[[1]\n",
            " [0]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bidireccional"
      ],
      "metadata": {
        "id": "k-ky33iDAl3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Bidirectional"
      ],
      "metadata": {
        "id": "6Bl4VhXPAiiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_bd = Sequential()\n",
        "model_bd.add(embedding_layer)\n",
        "model_bd.add(Bidirectional(layer=LSTM(units=64)))\n",
        "model_bd.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_bd.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "TbpZ0Zb-Axs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_bd.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhkDMp6oBBZc",
        "outputId": "3cd9044b-18e3-4651-d161-28b05d3a1b11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 4, 8)              152       \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              37376     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37,657\n",
            "Trainable params: 37,657\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_bd.fit(padded_reviews, labels, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2l3ui1zBD40",
        "outputId": "78a73102-cc59-40dc-d855-661ecca346e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6954 - accuracy: 0.3000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6876 - accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6799 - accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6722 - accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6646 - accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6569 - accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6492 - accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6414 - accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6335 - accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6255 - accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6173 - accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6090 - accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6004 - accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5916 - accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5825 - accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5732 - accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5635 - accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5535 - accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5431 - accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5323 - accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5211 - accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5095 - accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4974 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4848 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4716 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4580 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4438 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4290 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4137 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3978 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3813 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3644 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3469 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3290 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3107 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2920 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2732 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2541 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2351 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2162 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1976 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1793 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1617 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1448 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1288 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1137 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0998 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0871 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0756 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0653 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0562 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0483 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0414 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0355 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0304 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0261 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0225 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0194 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0169 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0147 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0129 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0114 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0101 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0090 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0081 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0018 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efea00c5f60>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_bd.predict(new_padded), '\\n', '----'*3)\n",
        "print(np.where(model_bd.predict(new_padded)>0.5, 1, 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE42cjRaCPoh",
        "outputId": "f83610a5-6d34-4331-a11c-f3d567c54d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7efea02a6200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 725ms/step\n",
            "[[0.998587  ]\n",
            " [0.00482868]\n",
            " [0.05373497]] \n",
            " ------------\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "[[1]\n",
            " [0]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Convolución 1D"
      ],
      "metadata": {
        "id": "9x5PO_Y6CYfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv1D, GlobalAveragePooling1D"
      ],
      "metadata": {
        "id": "bRWkbdk3CULo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Global Average Pooling](https://paperswithcode.com/method/global-average-pooling)"
      ],
      "metadata": {
        "id": "lYpX-zigD63n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_conv = Sequential()\n",
        "model_conv.add(embedding_layer)\n",
        "model_conv.add(Conv1D(filters=8, kernel_size=3, activation='relu'))\n",
        "model_conv.add(GlobalAveragePooling1D())\n",
        "model_conv.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_conv.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "pTM8tStsCurA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_conv.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjxSBdS1C9ii",
        "outputId": "86ba5713-cead-4b38-b0a7-4c31b34972a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 4, 8)              152       \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 2, 8)              200       \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 8)                0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 361\n",
            "Trainable params: 361\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_conv.fit(padded_reviews, labels, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4PaVf45DmB8",
        "outputId": "7dda4e92-0423-4395-a721-58641d586569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.6523 - accuracy: 0.7000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6466 - accuracy: 0.8000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6410 - accuracy: 0.9000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6355 - accuracy: 0.9000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6300 - accuracy: 0.9000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6246 - accuracy: 0.9000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6192 - accuracy: 0.9000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6140 - accuracy: 0.9000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6089 - accuracy: 0.9000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6040 - accuracy: 0.9000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5991 - accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5943 - accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5895 - accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5848 - accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5802 - accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5755 - accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5709 - accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5664 - accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5618 - accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5574 - accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5531 - accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5487 - accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5444 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5401 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5359 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5319 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5280 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5240 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5201 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5163 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5125 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5086 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5048 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5010 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4972 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4934 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4896 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4858 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4821 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4783 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4746 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4709 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4672 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4635 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4598 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4561 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4525 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4488 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4452 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4416 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4380 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4344 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4308 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4272 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4237 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4202 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4167 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4132 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4097 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4063 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4028 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3994 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3961 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3927 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3893 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3859 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3826 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3793 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3759 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3727 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3694 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3662 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3630 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3598 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3567 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3535 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3504 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3473 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3441 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3410 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3379 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3348 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3317 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3287 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3256 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3226 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3195 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3165 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3135 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3105 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3075 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3046 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3016 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2987 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2958 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2929 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2900 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2871 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2843 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2814 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efea016f250>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_conv.predict(new_padded), '\\n', '----'*3)\n",
        "print(np.where(model_conv.predict(new_padded)>0.5, 1, 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MrypyEQDsh5",
        "outputId": "3ba4f3f1-2816-40f2-82aa-4f94e7d4d9a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7efe99f29fc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 117ms/step\n",
            "[[0.7681727 ]\n",
            " [0.36779055]\n",
            " [0.26061252]] \n",
            " ------------\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "[[1]\n",
            " [0]\n",
            " [0]]\n"
          ]
        }
      ]
    }
  ]
}