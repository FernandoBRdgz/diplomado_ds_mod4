{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FernandoBRdgz/diplomado_ds_mod4/blob/main/4.4%20Modelado%20Secuencial/4.4.1%20Procesamiento%20del%20lenguaje.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cIAXR32W-23"
      },
      "source": [
        "#spaCy\n",
        "\n",
        "[spaCy](https://spacy.io/) es una librería de Python de código abierto que analiza y \"comprende\" grandes volúmenes de texto. Hay modelos separados disponibles que se adaptan a idiomas específicos (inglés, español, francés, alemán, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "XcintVErQbTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Tesla is looking at buying U.S. startup for $6 million'"
      ],
      "metadata": {
        "id": "NI7f4uE-Q0r1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sctdmYGhW-27",
        "outputId": "c25368f5-71ee-4868-ce07-47b855009ec4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "doc = nlp(text)\n",
        "type(doc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "    print(token.text, token.pos_, token.dep_, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9CqT6xgQwCe",
        "outputId": "da817ce3-579f-4b50-d87d-2a8fa842b936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla PROPN nsubj \n",
            "\n",
            "is AUX aux \n",
            "\n",
            "looking VERB ROOT \n",
            "\n",
            "at ADP prep \n",
            "\n",
            "buying VERB pcomp \n",
            "\n",
            "U.S. PROPN compound \n",
            "\n",
            "startup NOUN dobj \n",
            "\n",
            "for ADP prep \n",
            "\n",
            "$ SYM quantmod \n",
            "\n",
            "6 NUM compound \n",
            "\n",
            "million NUM pobj \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azielSOfW-3A"
      },
      "source": [
        "Esto no parece muy fácil de usar, pero de inmediato vemos que suceden algunas cosas interesantes:\n",
        "1. Se reconoce que Tesla es un nombre propio, no solo una palabra al comienzo de una oración.\n",
        "2. U.S. se mantiene unido como una sola entidad (lo llamamos \"token\")\n",
        "\n",
        "A medida que profundicemos en spaCy, veremos qué significa cada una de estas abreviaturas y cómo se derivan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L380zNDBW-3I"
      },
      "source": [
        "## Tokenización\n",
        "\n",
        "El primer paso en el procesamiento de texto es dividir todas las partes componentes (palabras y puntuación) en tokens. Estos tokens se anotan dentro del objeto `Doc` para contener información descriptiva."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgs7aOhNW-3J",
        "outputId": "8486a1e7-61fd-48d6-d647-b094965d5198",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla PROPN nsubj \n",
            "\n",
            "is AUX aux \n",
            "\n",
            "n't PART neg \n",
            "\n",
            "looking VERB ROOT \n",
            "\n",
            "  SPACE dep \n",
            "\n",
            "into ADP prep \n",
            "\n",
            "startups NOUN pobj \n",
            "\n",
            "anymore ADV advmod \n",
            "\n",
            ". PUNCT punct \n",
            "\n"
          ]
        }
      ],
      "source": [
        "doc2 = nlp(\"Tesla isn't looking  into startups anymore.\")\n",
        "\n",
        "for token in doc2:\n",
        "    print(token.text, token.pos_, token.dep_, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMrUMNSdW-3J"
      },
      "source": [
        "Observe cómo `isn't` se ha dividido en dos tokens. spaCy reconoce tanto el verbo raíz `is` como la negación adjunta. Observe también que tanto el espacio en blanco extendido como el punto al final de la oración tienen asignados sus propios tokens.\n",
        "\n",
        "Es importante tener en cuenta que aunque `doc2` contiene información procesada sobre cada token, también conserva el texto original:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2g1jzgnDW-3K",
        "outputId": "e6576edc-56cc-4e5c-f0d6-aec50c1d47cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tesla isn't looking  into startups anymore."
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "doc2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dis7tspW-3L",
        "outputId": "6855e623-0778-4fb7-c9bd-5c795683fd54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tesla"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "doc2[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQKJQebaW-3L",
        "outputId": "8380ee29-fe11-4811-c0c7-08e195869cd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.token.Token"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "type(doc2[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJcrXdStW-3M"
      },
      "source": [
        "## Etiquetado Gramatical (Part-of-Speech Tagging)\n",
        "\n",
        "Para obtener una lista completa de etiquetas POS, visite https://universaldependencies.org/u/pos/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sV4A0EBW-3M",
        "outputId": "6c9cd752-769c-4b2a-cb2e-f598a6b8ce3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PROPN'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "doc2[0].pos_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdQT_hXnW-3N"
      },
      "source": [
        "## Dependencias\n",
        "También analizamos las dependencias sintácticas asignadas a cada token. `Tesla` se identifica como `nsubj` o el ***sujeto nominal*** de la oración.\n",
        "\n",
        "Se puede encontrar una buena explicación de las dependencias escritas [aquí](https://nlp.stanford.edu/software/dependencies_manual.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EP39YF2jW-3N",
        "outputId": "2fcb0041-25ec-4b4f-f455-3cec919f32bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nsubj'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "doc2[0].dep_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O939v0F6W-3O"
      },
      "source": [
        "Para ver el nombre completo de una etiqueta, use `spacy.explain(tag)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WN7ekDbNW-3P",
        "outputId": "b592eadc-f3b7-4ed4-8629-4fe757cbb4d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'proper noun'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "spacy.explain('PROPN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2ZU00P1W-3Q",
        "outputId": "264d64cf-90c2-404f-b6b7-b60343a88db1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nominal subject'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "spacy.explain('nsubj')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdkFamLUW-3Q"
      },
      "source": [
        "## Atributos de tokens adicionales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qSm7a1wW-3Q"
      },
      "source": [
        "|Tag|Descripción|doc2[0].tag|\n",
        "|:------|:------:|:------|\n",
        "|`.text`|El texto original de la palabra<!-- .element: style=\"text-align:left;\" -->|`Tesla`|\n",
        "|`.lemma_`|La forma básica de la palabra|`tesla`|\n",
        "|`.pos_`|La etiqueta gramatical simple (POS)|`PROPN`/`proper noun`|\n",
        "|`.tag_`|La etiqueta gramatical detallada|`NNP`/`noun, proper singular`|\n",
        "|`.shape_`|La forma de la palabra: mayúsculas, puntuación, dígitos|`Xxxxx`|\n",
        "|`.is_alpha`|¿El token es un carácter alfabético?|`True`|\n",
        "|`.is_stop`|¿El token es parte de una lista de stopwords, es decir, de las palabras más comunes del idioma?|`False`|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pg_oUGGPW-3R",
        "outputId": "14c300ed-a86f-42fc-bbca-09fb936bbb5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "looking\n",
            "look\n"
          ]
        }
      ],
      "source": [
        "# Lemas (la forma base de la palabra):\n",
        "print(doc2[3].text)\n",
        "print(doc2[3].lemma_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ah6FV5zW-3R",
        "outputId": "72c85de9-2923-4693-fcbb-f46630658f83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VERB\n",
            "VBG / verb, gerund or present participle\n"
          ]
        }
      ],
      "source": [
        "# Parts-of-Speech Tagging:\n",
        "print(doc2[3].pos_)\n",
        "print(doc2[3].tag_ + ' / ' + spacy.explain(doc2[3].tag_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEsEUaIxW-3S",
        "outputId": "fc0b3f39-fede-463f-b595-51cbf70159b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla: Xxxxx\n",
            "U.S. : X.X.\n"
          ]
        }
      ],
      "source": [
        "# Formas de la palabra:\n",
        "print(doc2[0].text+': '+doc2[0].shape_)\n",
        "print(doc[5].text+' : '+doc[5].shape_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUTMo5t1W-3S",
        "outputId": "5e2eb897-6bbe-4456-958b-1f371fbb2bb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "# Valores booleanos:\n",
        "print(doc2[0].is_alpha)\n",
        "print(doc2[0].is_stop)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oahj8UrqW-3T"
      },
      "source": [
        "## Spans (tramos)\n",
        "\n",
        "A veces puede ser difícil trabajar con objetos grandes de un `Doc`. Un *span* es una porción del objeto `Doc` de la forma `Doc[start:stop]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oS3QHlVQW-3T"
      },
      "outputs": [],
      "source": [
        "doc3 = nlp('Although commmonly attributed to John Lennon from his song \"Beautiful Boy\", \\\n",
        "the phrase \"Life is what happens to us while we are making other plans\" was written by \\\n",
        "cartoonist Allen Saunders and published in Reader\\'s Digest in 1957, when Lennon was 17.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "948yZzCmW-3T",
        "outputId": "d9b04480-4345-4f42-fcae-218f55bdbf32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Life is what happens to us while we are making other plans\"\n"
          ]
        }
      ],
      "source": [
        "life_quote = doc3[16:30]\n",
        "print(life_quote)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKV98Cz4W-3U",
        "outputId": "a2687786-6ec4-4dbb-d32d-19fdc36b482e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.span.Span"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "type(life_quote)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnhJdDRvW-3V"
      },
      "source": [
        "## Oraciones\n",
        "\n",
        "Ciertos tokens dentro de un objeto `Doc` también pueden recibir una etiqueta de \"Comienzo de oración\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uyH_PRdW-3V"
      },
      "outputs": [],
      "source": [
        "doc4 = nlp('This is the first sentence. This is another sentence. This is the last sentence.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33v4v0T9W-3V",
        "outputId": "79357383-49c6-4e3e-bd3b-fd31dc32d63b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the first sentence. \n",
            "\n",
            "This is another sentence. \n",
            "\n",
            "This is the last sentence. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for sent in doc4.sents:\n",
        "    print(sent, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_ErK_yLW-3W",
        "outputId": "736bcbec-22bd-487d-fad0-9bdf8166d902",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "doc4[6].is_sent_start"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conteo de Tokens\n",
        "\n",
        "Los objetos `Doc` tienen un número determinado de tokens haciendo posible su conteo."
      ],
      "metadata": {
        "id": "hkz4lLJkY7Wo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea una cadena de texto que incluye comillas de apertura y cierre\n",
        "\n",
        "mystring = '\"We\\'re moving to L.A.!\"'\n",
        "print(mystring)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbrzNLsnYaYU",
        "outputId": "c0549663-534c-4f33-a001-1287d680d9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"We're moving to L.A.!\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc5 = nlp(mystring)\n",
        "\n",
        "for token in doc5:\n",
        "    print(token.text, end=' | ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOp7PlHxYdSj",
        "outputId": "e2595c98-054f-45a6-daca-53f628e18ab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\" | We | 're | moving | to | L.A. | ! | \" | "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(doc5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T351AU6mYfJi",
        "outputId": "4fb3d679-a7b9-4597-aa5b-81af28e3a231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entidades Nombradas\n",
        "\n",
        "Las entidades nombradas agregan otra capa de contexto. El modelo de lenguaje reconoce que ciertas palabras son nombres de organizaciones mientras que otras son ubicaciones, y otras combinaciones se relacionan con dinero, fechas, etc. Las entidades nombradas son accesibles a través de la propiedad `ent` de un objeto `Doc`."
      ],
      "metadata": {
        "id": "OQ2VRALMZqQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc6 = nlp('Apple will build a factory in Hong Kong for $6 million')\n",
        "\n",
        "for token in doc6:\n",
        "    print(token.text, end=' | ')\n",
        "\n",
        "print('\\n----')\n",
        "\n",
        "for ent in doc6.ents:\n",
        "    print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxFme4VhZPx1",
        "outputId": "7ce6a032-3d27-4ef1-a104-b7c5ed66ef12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple | will | build | a | factory | in | Hong | Kong | for | $ | 6 | million | \n",
            "----\n",
            "Apple - ORG - Companies, agencies, institutions, etc.\n",
            "Hong Kong - GPE - Countries, cities, states\n",
            "$6 million - MONEY - Monetary values, including unit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observe cómo se combinan dos tokens para formar la entidad 'Hong Kong', y cómo se combinan tres tokens para formar la entidad monetaria: '$6 millones'"
      ],
      "metadata": {
        "id": "L1SBTt44Zzo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(doc6.ents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqjsQo1GZtKF",
        "outputId": "ab33468f-3aa6-46ee-9dbb-fbc91ad45bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizadores incorporados\n",
        "\n",
        "spaCy incluye una herramienta de visualización integrada llamada **displaCy**.\n",
        "\n",
        "Para obtener más información, visite https://spacy.io/usage/visualizers"
      ],
      "metadata": {
        "id": "R7q4GFkaaQND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "\n",
        "doc7 = nlp('Apple is going to build a U.K. factory for $6 million.')\n",
        "displacy.render(doc7, style='dep', jupyter=True, options={'distance': 110})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "lhAik5XGZ1lx",
        "outputId": "8576045f-5f40-47bc-983a-66ea102a2842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"125ce13ca5344fe5936edd7215b1942b-0\" class=\"displacy\" width=\"1370\" height=\"357.0\" direction=\"ltr\" style=\"max-width: none; height: 357.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">going</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">build</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">U.K.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">factory</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">for</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">$</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">SYM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">6</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1260\">million.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1260\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-125ce13ca5344fe5936edd7215b1942b-0-0\" stroke-width=\"2px\" d=\"M70,222.0 C70,112.0 260.0,112.0 260.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-125ce13ca5344fe5936edd7215b1942b-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,224.0 L62,212.0 78,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-125ce13ca5344fe5936edd7215b1942b-0-1\" stroke-width=\"2px\" d=\"M180,222.0 C180,167.0 255.0,167.0 255.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-125ce13ca5344fe5936edd7215b1942b-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M180,224.0 L172,212.0 188,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-125ce13ca5344fe5936edd7215b1942b-0-2\" stroke-width=\"2px\" d=\"M400,222.0 C400,167.0 475.0,167.0 475.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-125ce13ca5344fe5936edd7215b1942b-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M400,224.0 L392,212.0 408,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-125ce13ca5344fe5936edd7215b1942b-0-3\" stroke-width=\"2px\" d=\"M290,222.0 C290,112.0 480.0,112.0 480.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-125ce13ca5344fe5936edd7215b1942b-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M480.0,224.0 L488.0,212.0 472.0,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-125ce13ca5344fe5936edd7215b1942b-0-4\" stroke-width=\"2px\" d=\"M620,222.0 C620,112.0 810.0,112.0 810.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-125ce13ca5344fe5936edd7215b1942b-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M620,224.0 L612,212.0 628,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-125ce13ca5344fe5936edd7215b1942b-0-5\" stroke-width=\"2px\" d=\"M730,222.0 C730,167.0 805.0,167.0 805.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-125ce13ca5344fe5936edd7215b1942b-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M730,224.0 L722,212.0 738,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-125ce13ca5344fe5936edd7215b1942b-0-6\" stroke-width=\"2px\" d=\"M510,222.0 C510,57.0 815.0,57.0 815.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-125ce13ca5344fe5936edd7215b1942b-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M815.0,224.0 L823.0,212.0 807.0,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-125ce13ca5344fe5936edd7215b1942b-0-7\" stroke-width=\"2px\" d=\"M510,222.0 C510,2.0 930.0,2.0 930.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-125ce13ca5344fe5936edd7215b1942b-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M930.0,224.0 L938.0,212.0 922.0,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-125ce13ca5344fe5936edd7215b1942b-0-8\" stroke-width=\"2px\" d=\"M1060,222.0 C1060,112.0 1250.0,112.0 1250.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-125ce13ca5344fe5936edd7215b1942b-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1060,224.0 L1052,212.0 1068,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-125ce13ca5344fe5936edd7215b1942b-0-9\" stroke-width=\"2px\" d=\"M1170,222.0 C1170,167.0 1245.0,167.0 1245.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-125ce13ca5344fe5936edd7215b1942b-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1170,224.0 L1162,212.0 1178,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-125ce13ca5344fe5936edd7215b1942b-0-10\" stroke-width=\"2px\" d=\"M950,222.0 C950,57.0 1255.0,57.0 1255.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-125ce13ca5344fe5936edd7215b1942b-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1255.0,224.0 L1263.0,212.0 1247.0,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El argumento opcional `'distance'` establece la distancia entre tokens. Si la distancia se hace demasiado pequeña, el texto que aparece debajo de las flechas cortas puede quedar demasiado comprimido para leer."
      ],
      "metadata": {
        "id": "FXMSVaC3aY0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando entidades nombradas\n",
        "\n",
        "doc8 = nlp('Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million.')\n",
        "displacy.render(doc8, style='ent', jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "R02IaqBeaLny",
        "outputId": "8b979486-ba90-48c9-e859-1f74588a4509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the last quarter\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " sold \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    nearly 20 thousand\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    iPods\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
              "</mark>\n",
              " for a profit of \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    $6 million\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              ".</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lematización\n",
        "\n",
        "A diferencia de el stemming, la lematización va más allá de la reducción de palabras y considera el vocabulario completo de un idioma para aplicar un *análisis morfológico* a las palabras. El lema de `'was'` es `'be'` y el lema de `'mice'` es `'mouse'`. Además, el lema de `'meeting'` podría ser `'meet'` o `'meeting'` dependiendo de su uso en una oración."
      ],
      "metadata": {
        "id": "6cqkpEZ-cZiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc9 = nlp(u\"I am a runner running in a race because I love to run since I ran today\")\n",
        "\n",
        "for token in doc9:\n",
        "    print(token.text, '\\t\\t', token.pos_, '\\t\\t', token.lemma, '\\t\\t', token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMARmDyzadx9",
        "outputId": "a53acf01-114a-4ef8-9356-4d239783eece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I \t\t PRON \t\t 4690420944186131903 \t\t I\n",
            "am \t\t AUX \t\t 10382539506755952630 \t\t be\n",
            "a \t\t DET \t\t 11901859001352538922 \t\t a\n",
            "runner \t\t NOUN \t\t 12640964157389618806 \t\t runner\n",
            "running \t\t VERB \t\t 12767647472892411841 \t\t run\n",
            "in \t\t ADP \t\t 3002984154512732771 \t\t in\n",
            "a \t\t DET \t\t 11901859001352538922 \t\t a\n",
            "race \t\t NOUN \t\t 8048469955494714898 \t\t race\n",
            "because \t\t SCONJ \t\t 16950148841647037698 \t\t because\n",
            "I \t\t PRON \t\t 4690420944186131903 \t\t I\n",
            "love \t\t VERB \t\t 3702023516439754181 \t\t love\n",
            "to \t\t PART \t\t 3791531372978436496 \t\t to\n",
            "run \t\t VERB \t\t 12767647472892411841 \t\t run\n",
            "since \t\t SCONJ \t\t 10066841407251338481 \t\t since\n",
            "I \t\t PRON \t\t 4690420944186131903 \t\t I\n",
            "ran \t\t VERB \t\t 12767647472892411841 \t\t run\n",
            "today \t\t NOUN \t\t 11042482332948150395 \t\t today\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la oración anterior, `running`, `run` y `ran` apuntan al mismo lema `run`."
      ],
      "metadata": {
        "id": "p3L5HurtciUR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Función para mostrar lemas\n",
        "\n",
        "Dado que la celda anterior está escalonada, es difícil de leer, por lo que se escribe una función que muestre la información que queremos de forma más clara."
      ],
      "metadata": {
        "id": "DJ2FwzCbclUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_lemmas(text):\n",
        "    for token in text:\n",
        "        print(f'{token.text:{12}} {token.pos_:{6}} {token.lemma:<{22}} {token.lemma_}')"
      ],
      "metadata": {
        "id": "IcdoTcFkccwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_lemmas(doc9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPf4_etCO82w",
        "outputId": "a5daf1bd-3589-483b-ee4a-9a375ed8ea92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I            PRON   4690420944186131903    I\n",
            "am           AUX    10382539506755952630   be\n",
            "a            DET    11901859001352538922   a\n",
            "runner       NOUN   12640964157389618806   runner\n",
            "running      VERB   12767647472892411841   run\n",
            "in           ADP    3002984154512732771    in\n",
            "a            DET    11901859001352538922   a\n",
            "race         NOUN   8048469955494714898    race\n",
            "because      SCONJ  16950148841647037698   because\n",
            "I            PRON   4690420944186131903    I\n",
            "love         VERB   3702023516439754181    love\n",
            "to           PART   3791531372978436496    to\n",
            "run          VERB   12767647472892411841   run\n",
            "since        SCONJ  10066841407251338481   since\n",
            "I            PRON   4690420944186131903    I\n",
            "ran          VERB   12767647472892411841   run\n",
            "today        NOUN   11042482332948150395   today\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc10 = nlp(\"I saw eighteen mice today!\")\n",
        "show_lemmas(doc10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbV-vf--c3BE",
        "outputId": "9154d3c0-70e4-497f-998a-d8c1dc44b64f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I            PRON   4690420944186131903    I\n",
            "saw          VERB   11925638236994514241   see\n",
            "eighteen     NUM    9609336664675087640    eighteen\n",
            "mice         NOUN   1384165645700560590    mouse\n",
            "today        NOUN   11042482332948150395   today\n",
            "!            PUNCT  17494803046312582752   !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observe que el lema de `saw` es `see`, `mice` es la forma plural de `mouse` y, sin embargo, `eighteen` es su propio número, *no* una forma expandida de `eight`."
      ],
      "metadata": {
        "id": "xVsvsMVXdCRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc11 = nlp(\"I am meeting him tomorrow at the meeting.\")\n",
        "show_lemmas(doc11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1MS8BmBc9ft",
        "outputId": "c84a31d7-6337-4368-dd7e-f53dd379bbe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I            PRON   4690420944186131903    I\n",
            "am           AUX    10382539506755952630   be\n",
            "meeting      VERB   6880656908171229526    meet\n",
            "him          PRON   1655312771067108281    he\n",
            "tomorrow     NOUN   3573583789758258062    tomorrow\n",
            "at           ADP    11667289587015813222   at\n",
            "the          DET    7425985699627899538    the\n",
            "meeting      NOUN   14798207169164081740   meeting\n",
            ".            PUNCT  12646065887601541794   .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí el lema `meeting` está determinado por el contexto de la oración."
      ],
      "metadata": {
        "id": "dXznqj4ldIOS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stop Words\n",
        "\n",
        "Palabras como `a` y `the` aparecen con tanta frecuencia que no requieren un etiquetado tan exhaustivo como los sustantivos, los verbos y los modificadores. Las llamamos stopwords o *palabras vacías* y se pueden filtrar del texto que se va a procesar. spaCy tiene una lista integrada de palabras vacías en varios idiomas."
      ],
      "metadata": {
        "id": "j5EnDMhzfidb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conjunto de palabras vacías predeterminadas de spaCy (recuerde que los conjuntos no tienen un orden):\n",
        "print(nlp.Defaults.stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwpApF3ldKWT",
        "outputId": "0a018e5d-8b23-48b4-c6d4-5b34fcc5b2a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'why', 'this', '’ll', 'for', 'himself', 'not', 'therefore', 'toward', 'you', 'seems', 'behind', 'seemed', '’m', 'almost', 'amongst', 'sixty', 'thereafter', 'their', 'anything', 'we', 'has', 'when', 'ever', 'each', 'becoming', 'mine', 'really', 'in', 'because', 'n‘t', 'is', 'during', 'doing', 'three', 'becomes', 'of', 'were', 'often', 'am', 'could', 'any', 'yours', 'except', 'front', 'afterwards', 'none', 'call', 'per', 'many', '‘ll', 'bottom', 'else', 'always', 'so', 'nor', 'though', 'upon', 'would', 'few', 'indeed', 'fifteen', 'which', 'i', 'and', 'who', 'at', 'again', 'the', 'too', 'a', 'from', 'as', 'whereas', 'yourself', 'ours', 'beforehand', 'ten', 'wherein', 'against', 'that', 'perhaps', 'to', 'via', 'have', 'over', 'does', 'used', 'neither', 'several', 'across', 'every', 'well', 'moreover', 'only', 'besides', 'take', 'part', 'elsewhere', '‘m', 'hereafter', 'nevertheless', 'put', 'between', 'within', 'around', 'such', 'everyone', 'no', 'further', '‘d', 'nobody', 'cannot', 'wherever', 'therein', 'using', 'unless', 'most', 'even', 'please', 'below', 'here', 'an', 'they', 'twelve', 'on', 'been', 'throughout', 'with', 'thereupon', 'some', 'if', 'will', 'eleven', 'side', 'somehow', 'still', 'may', 'third', 'her', 'full', 'all', 'through', 'are', 'either', 'meanwhile', 'also', 'whereafter', 'hereby', 'show', 'somewhere', 'thru', 'last', 'beside', 'hereupon', 'there', 'under', 'everything', 'me', 'can', 'hundred', 'herein', 'up', 'whereupon', '’s', 'go', 'get', 'others', 'hence', 'first', 'empty', 'while', 'but', 'about', 'another', 'less', '’d', 'together', 'something', 'where', 'alone', 'same', 'yet', 'one', 'whole', 're', '‘ve', 'name', 'thence', 'what', \"'d\", \"n't\", 'hers', 'whether', 'amount', 'four', 'towards', 'without', 'my', 'enough', 'however', \"'ve\", 'then', 'how', 'he', '‘s', 'seeming', 'ourselves', 'anyhow', \"'s\", 'sometimes', 'both', 'noone', 'very', 'since', 'latter', '’ve', 'before', 'thus', 'herself', 'various', 'itself', 'whatever', 'next', 'whither', \"'m\", 'serious', 'ca', 'six', 'more', 'out', 'whereby', \"'re\", 'his', 'had', 'beyond', 'until', 'myself', 'n’t', 'twenty', 'although', 'did', '’re', 'once', 'down', 'just', 'might', 'top', 'whose', 'move', 'regarding', 'being', 'whenever', 'nowhere', 'back', 'someone', 'already', 'should', 'latterly', 'rather', 'those', 'fifty', 'anyone', 'it', 'whom', 'other', 'made', 'after', 'quite', 'eight', 'our', 'see', '‘re', 'along', 'make', 'above', 'forty', 'us', 'own', 'do', 'say', 'formerly', 'yourselves', 'your', 'off', 'thereby', 'anywhere', 'never', 'keep', 'by', 'five', 'whoever', 'or', 'everywhere', 'themselves', \"'ll\", 'be', 'done', 'otherwise', 'nine', 'much', 'seem', 'must', 'was', 'now', 'these', 'became', 'nothing', 'them', 'onto', 'former', 'into', 'she', 'anyway', 'him', 'two', 'least', 'than', 'its', 'among', 'due', 'whence', 'sometime', 'mostly', 'give', 'become', 'namely'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(nlp.Defaults.stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6GqsSVdfl9A",
        "outputId": "6b11d6be-2f66-4176-860c-1934bdb6cbbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Para ver si una palabra es una stopword"
      ],
      "metadata": {
        "id": "tHX482lSR91M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.vocab['myself'].is_stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnIz_woHfoKP",
        "outputId": "f3106682-0cf4-4783-e090-2c6396cb6a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.vocab['mystery'].is_stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-oHGHg8fxSe",
        "outputId": "287a917f-8263-4bdc-a369-54c0a8263f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Para agregar una stopword\n",
        "\n",
        "Puede haber ocasiones en las que desee agregar una palabra vacía al conjunto predeterminado. Tal vez decidas que `'btw'` (abreviatura común para \"*by the way*\") debe considerarse una palabra vacía."
      ],
      "metadata": {
        "id": "I9Yf6cwsf039"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agregue la palabra al conjunto de palabras vacías. ¡Use minúsculas!\n",
        "nlp.Defaults.stop_words.add('btw')\n",
        "\n",
        "# Establece la etiqueta stop_word en el lexema\n",
        "nlp.vocab['btw'].is_stop = True"
      ],
      "metadata": {
        "id": "NONp7udYfxqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(nlp.Defaults.stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGCfZ3xEf3cS",
        "outputId": "bf98abe7-da91-4d72-f882-7ea8689318d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "327"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.vocab['btw'].is_stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZcLHDZKf6Tf",
        "outputId": "6cf3b213-b5e0-4e4c-ad19-ac8661399e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Para eliminar una stopword\n",
        "\n",
        "Alternativamente, puede decidir que `'beyond'` no debe considerarse una palabra vacía."
      ],
      "metadata": {
        "id": "F3r1-AjvgEWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Elimina la palabra del conjunto de palabras vacías\n",
        "#nlp.Defaults.stop_words.remove('beyond')\n",
        "\n",
        "# Elimina la etiqueta stop_word del lexema\n",
        "nlp.vocab['beyond'].is_stop = False"
      ],
      "metadata": {
        "id": "xscwbYwdf8Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(nlp.Defaults.stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67nG55MdgCMK",
        "outputId": "21e88b3c-02da-44be-8963-03df143d7c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "327"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.vocab['beyond'].is_stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUQreqAggGot",
        "outputId": "5d0be239-c901-440f-a0ff-371a58f1fba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}