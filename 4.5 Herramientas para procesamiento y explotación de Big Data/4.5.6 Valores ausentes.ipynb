{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FernandoBRdgz/diplomado_ds_mod4/blob/main/4.5%20Herramientas%20para%20procesamiento%20y%20explotaci%C3%B3n%20de%20Big%20Data/4.5.6%20Valores%20ausentes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Valores ausentes\n",
        "\n",
        "A menudo, las fuentes de datos están incompletas, lo que significa que le faltarán datos, tiene 3 opciones básicas para completar los datos faltantes. Usted personalmente tendrá que tomar la decisión de cuál es el enfoque correcto dependiendo de su situación:\n",
        "\n",
        "* Mantener los valores faltantes\n",
        "* Eliminar los registros/columnas con valores faltantes\n",
        "* Imputar con algún otro valor"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "e54a6dfe-7602-4aa4-8f6a-e2b65d3924fc"
        },
        "id": "gHtH2TJQYLIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation = \"mod4gen<x>\""
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "940bd7c6-9f8f-4252-9a72-3eda5583c50d"
        },
        "id": "1BYqI13LYLIz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(f\"/mnt/{generation}/input/contains_null.csv\", inferSchema=True, header=True)"
      ],
      "metadata": {
        "collapsed": true,
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "aff41416-3d28-4613-a8bc-231c24338061"
        },
        "id": "yUk6m-NJYLI0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.display()"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "e5825d1f-9e8f-43ae-b822-223fdfacb341"
        },
        "id": "WJeunJ8IYLI0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Eliminación de valores ausentes"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "a977d731-fe83-43e4-9a49-440d92291980"
        },
        "id": "vJBspR4uYLI1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es posible usar el método `.na` para trabajar con datos faltantes. El comando `drop()` tiene los siguientes parámetros:\n",
        "\n",
        "    df.na.drop(how='any', thresh=None, subset=None)\n",
        "    \n",
        "    * param how: 'any' or 'all'.\n",
        "    \n",
        "        If 'any', drop a row if it contains any nulls.\n",
        "        If 'all', drop a row only if all its values are null.\n",
        "    \n",
        "    * param thresh: int, default None\n",
        "    \n",
        "        If specified, drop rows that have less than `thresh` non-null values.\n",
        "        This overwrites the `how` parameter.\n",
        "        \n",
        "    * param subset:\n",
        "        optional list of column names to consider."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "f8c2bf72-d58a-41a9-8e52-1e87f8e12c36"
        },
        "id": "Yp1Zf2-oYLI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tirar cualquier fila que contenga datos faltantes\n",
        "df.na.drop().display()"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "f7c669ee-2b12-4672-b6c8-38f90b7fe619"
        },
        "id": "PCkoM-AhYLI1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.drop(how='any').display()"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "428c5399-0268-4fe7-8499-15054aa9c9d0"
        },
        "id": "HYqmgSGKYLI2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Retiene el registro si se cumple la condición de contener menos de 2 valores faltantes\n",
        "df.na.drop(thresh=2).display()"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "00206967-12ca-4644-a825-71cc7a8700e6"
        },
        "id": "4m-myHDDYLI2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Elimina valores faltantes para una variable específica\n",
        "df.na.drop(subset=[\"Sales\"]).display()"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "dc33364f-08cc-4421-b027-031dec3d267e"
        },
        "id": "BffHIxYPYLI2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.drop(how='all').display()"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "df27385c-aeed-44c3-8c89-8382a21ee715"
        },
        "id": "DstodI-gYLI3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(\"Name\").display()"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "62f9b0e9-35d7-4e67-808e-8ea04625c905"
        },
        "id": "ftwEC194YLI3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imputación\n",
        "\n",
        "También podemos imputar nuevos valores. Si se cuenta con valores nulos en variable con distintos tipos de datos, Spark es lo suficientemente \"inteligente\" como para hacer coincidir los tipos de datos."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "b95a177b-9fb8-4a03-9cb0-482c7a62efec"
        },
        "id": "iDXfRCi0YLI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.fill('MISSING').display()"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "fa8886ed-0db2-4523-b393-0d4b51f968bd"
        },
        "id": "8TeT3tJ_YLI3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.fill(0).display()"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "5d1135cf-2385-4480-9d10-0b1d05dd541d"
        },
        "id": "EGNoNQGMYLI4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Sin embargo, se recomienda especificar las columnas que se desean imputar junto con su respectivo valor\n",
        "df.na.fill('No Name', subset=['Name']).display()"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "1d34f688-7f66-4613-8443-73a251a4b1a0"
        },
        "id": "rZ13khuXYLI4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import mean"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "c829731b-8d6f-4f2a-b6aa-6c999edd927a"
        },
        "id": "6tMfxbp6YLI4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "mean_val = df.select(mean(df[\"Sales\"])).collect()\n",
        "mean_val[0][0]"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "39c358f1-c432-496c-b5b1-1107c52133b3"
        },
        "id": "8csXK39fYLI4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "mean_sales = mean_val[0][0]"
      ],
      "metadata": {
        "collapsed": true,
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "eed7918c-5288-4266-a19a-1fd51f3e4bbe"
        },
        "id": "FdzaXNBCYLI4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.fill(mean_sales, subset=[\"Sales\"]).display()"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "23c126a0-0d15-47e1-862f-88576a2fcdd8"
        },
        "id": "fC2NiOceYLI4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Misma operación de imputación pero en una solo línea de código\n",
        "df.na.fill(df.select(mean(df[\"Sales\"])).collect()[0][0], [\"Sales\"]).display()"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "c1914e8c-14e7-40ee-8bc7-9a52138c872f"
        },
        "id": "9u3ciRJ5YLI5"
      },
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [conda root]",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "version": "3.5.3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "application/vnd.databricks.v1+notebook": {
      "notebookName": "4.5.6 Valores ausentes",
      "dashboards": [],
      "notebookMetadata": {
        "pythonIndentUnit": 4
      },
      "language": "python",
      "widgets": {},
      "notebookOrigID": 267889027352992
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}